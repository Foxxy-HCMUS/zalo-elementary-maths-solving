{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/hotel/phit/miniconda3/envs/zalo/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'choices', 'explanation', 'answer', 'clean_choices', 'clean_answer', 'A', 'B', 'C', 'D', 'id'],\n",
       "        num_rows: 1080\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'choices', 'explanation', 'answer', 'clean_choices', 'clean_answer', 'A', 'B', 'C', 'D', 'id'],\n",
       "        num_rows: 120\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import get_peft_config, get_peft_model, PromptTuningInit, PromptTuningConfig, TaskType, PeftType\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset, load_from_disk, Dataset, concatenate_datasets\n",
    "import pandas as pd\n",
    "from transformers import ( \n",
    "                        Trainer,\n",
    "                        TrainingArguments,\n",
    "                        AutoTokenizer,\n",
    "                        AutoConfig,\n",
    "                        AutoModel,\n",
    "                        AutoModelForCausalLM,\n",
    "                        AutoModelForMultipleChoice,\n",
    "                        AutoModelForSeq2SeqLM,\n",
    "                        default_data_collator,\n",
    "                        get_linear_schedule_with_warmup,\n",
    "                        TextStreamer)\n",
    "import random\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "VER = 12\n",
    "V1_MODEL = True\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "  \n",
    "# model_path = \"vinai/PhoGPT-7B5-Instruct\" \n",
    "mmlu_dataset = load_dataset(\"lukaemon/mmlu\", \"elementary_mathematics\", cache_dir=\"./cache\")\n",
    "mathqa_dataset = load_dataset(\"math_qa\", cache_dir=\"./cache\")\n",
    "merged_dataset = mmlu_dataset[\"train\"]\n",
    "for subset_name, subset_data in mmlu_dataset.items():\n",
    "    if subset_name != 'train':\n",
    "        merged_dataset = concatenate_datasets([merged_dataset, subset_data])\n",
    "\n",
    "eng_dataset = load_from_disk(\"processed_train_eng.hf\")\n",
    "eng_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'explanation', 'choices', 'clean_answer', 'A', 'B', 'C', 'D', 'answer'],\n",
       "    num_rows: 37297\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "import random\n",
    "\n",
    "mathqa_concat_dataset = mathqa_dataset[\"train\"]\n",
    "for subset_name, subset_data in mathqa_dataset.items():\n",
    "    if subset_name != 'train':\n",
    "        mathqa_concat_dataset = concatenate_datasets([mathqa_concat_dataset, subset_data])\n",
    "\n",
    "mathqa_concat_dataset = mathqa_concat_dataset.rename_columns({\n",
    "    \"Problem\": \"question\",\n",
    "    \"Rationale\": \"explanation\",\n",
    "    \"correct\": \"clean_answer\",\n",
    "    \"options\": \"choices\"\n",
    "})\n",
    "\n",
    "mathqa_concat_dataset = mathqa_concat_dataset.remove_columns(column_names=[\"annotated_formula\", \"linear_formula\", \"category\"])\n",
    "choices = {choice: i for i, choice in enumerate(\"ABCD\")} \n",
    "idx2choices = {i: choice for i, choice in enumerate(\"ABCD\")} \n",
    "pattern = re.compile(\"[abcde] \\)\")\n",
    "def process_options(example):\n",
    "    options = example[\"choices\"].split(\", \")\n",
    "    example[\"choices\"] = options\n",
    "    if example[\"clean_answer\"] == \"e\":\n",
    "        idx = random.randint(0, 3)\n",
    "        options[idx], options[-1] = options[-1], options[idx]\n",
    "        example[\"clean_answer\"] = idx2choices[idx]\n",
    "    for choice, i in choices.items():\n",
    "        example[choice] = re.sub(pattern, \"\", options[i]).replace(\"'\", \"\").replace(\"]\", \"\").replace(\"[\", \"\").strip()\n",
    "    \n",
    "    example[\"clean_answer\"] = example[\"clean_answer\"].upper() \n",
    "    example[\"answer\"] = options[choices[example[\"clean_answer\"]]]\n",
    "    \n",
    "    return example\n",
    "\n",
    "mathqa_concat_dataset = mathqa_concat_dataset.map(process_options)\n",
    "mathqa_concat_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'A', 'B', 'C', 'D', 'clean_answer', 'explanation', 'answer'],\n",
       "    num_rows: 421\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_dataset = merged_dataset.rename_columns({\n",
    "    \"input\": \"question\",\n",
    "    \"target\": \"clean_answer\",\n",
    "})\n",
    "merged_dataset = merged_dataset.add_column(\"explanation\", [\"\"] * len(merged_dataset))\n",
    "def add_answer(example):\n",
    "    example[\"answer\"] = example[example[\"clean_answer\"]]\n",
    "    return example\n",
    "merged_dataset = merged_dataset.map(add_answer)\n",
    "merged_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'choices', 'explanation', 'answer', 'clean_choices', 'clean_answer', 'A', 'B', 'C', 'D', 'id'],\n",
       "        num_rows: 38798\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'choices', 'explanation', 'answer', 'clean_choices', 'clean_answer', 'A', 'B', 'C', 'D', 'id'],\n",
       "        num_rows: 120\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_dataset[\"train\"] = concatenate_datasets([eng_dataset[\"train\"], merged_dataset, mathqa_concat_dataset])\n",
    "eng_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"1,5\".isnumeric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'choices', 'clean_choices', 'A', 'B', 'C', 'D', 'id'],\n",
       "    num_rows: 189\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import ( \n",
    "                        AutoTokenizer,\n",
    "                        AutoModelForSeq2SeqLM)\n",
    "import torch\n",
    "import re\n",
    "import json \n",
    "\n",
    "test = json.loads(open('data/math_test.json').read())[\"data\"]\n",
    "test_df = pd.DataFrame(test)\n",
    "test_df.set_index(\"id\", inplace=True)\n",
    "\n",
    "pattern = re.compile(\"[ABCD].\")\n",
    "\n",
    "def process(texts):\n",
    "    return [pattern.split(text)[-1].strip() for text in texts]\n",
    "test_df[\"clean_choices\"] = test_df[\"choices\"].apply(process)\n",
    "\n",
    "choices = {choice: i for i, choice in enumerate(\"ABCD\")} \n",
    "\n",
    "def make_choice(df, choice):\n",
    "    idx = choices[choice]\n",
    "    df[choice] = df[\"clean_choices\"].apply(lambda x: x[idx] if idx < len(x) else \"\")\n",
    "    return df\n",
    "for choice in choices.keys():\n",
    "    make_choice(test_df, choice)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tokenizer_vi2en = AutoTokenizer.from_pretrained(\"vinai/vinai-translate-vi2en-v2\", src_lang=\"vi_VN\", cache_dir=\"./cache\")\n",
    "model_vi2en = AutoModelForSeq2SeqLM.from_pretrained(\"vinai/vinai-translate-vi2en-v2\", cache_dir=\"./cache\")\n",
    "device_vi2en = torch.device(\"cuda\")\n",
    "model_vi2en.to(device_vi2en)\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    number_replacements = []\n",
    "    def replace_numbers(match):\n",
    "        number = match.group(0)\n",
    "        number_replacements.append(number)\n",
    "        return \"NUMBER\"\n",
    "\n",
    "    # Replace numbers with a placeholder\n",
    "    text = re.sub(r'(\\d+)', replace_numbers, text)\n",
    "    return text, number_replacements\n",
    "\n",
    "def restore_numbers(translated_text, number_replacements):\n",
    "    for number in number_replacements:\n",
    "        translated_text = translated_text.replace(\"NUMBER\", number, 1)\n",
    "    return translated_text\n",
    "\n",
    "units = {\"kg\": \"kg\", \n",
    "         \"km\": \"km\", \n",
    "         \"km/giờ\": \"km/giờ\",\n",
    "         \"cm\": \"cm\", \n",
    "         \"cm2\": \"cm2\",\n",
    "         \"đồng\": \"VND\",\n",
    "         \"%\": \"%\",\n",
    "         \"dm\": \"dm\",\n",
    "         \"phút\": \"minutes\",\n",
    "         \"giờ\": \"hours\",\n",
    "         \"giây\": \"seconds\",}\n",
    "\n",
    "\n",
    "def check_number(choice):\n",
    "    # choice = str(choice)\n",
    "    check = False\n",
    "    for unit, eng_unit in units.items():\n",
    "        if unit in choice:\n",
    "            choice = choice.replace(unit, eng_unit)\n",
    "            check = True\n",
    "    if len(re.findall(\"(\\d+[%gm])\", choice)) > 0 or choice.replace(\" \", \"\").replace(\",\", \"\").replace(\".\", \"\").isnumeric():\n",
    "        check = True\n",
    "    if choice == \"\":\n",
    "        check = True\n",
    "    return check, choice\n",
    "    \n",
    "    \n",
    "def translate_choice(example):\n",
    "    for col in [\"question\", \"A\", \"B\", \"C\", \"D\"]:\n",
    "        # print(example[col])\n",
    "        if col in \"ABCD\":\n",
    "            check, example[col] = check_number(example[col])\n",
    "            if check:\n",
    "                continue\n",
    "        \n",
    "        input_ids = tokenizer_vi2en(example[col], padding=True, return_tensors=\"pt\").to(device_vi2en)\n",
    "        output_ids = model_vi2en.generate(\n",
    "            **input_ids,\n",
    "            decoder_start_token_id=tokenizer_vi2en.lang_code_to_id[\"en_XX\"],\n",
    "            num_return_sequences=1,\n",
    "            num_beams=1,\n",
    "            early_stopping=True\n",
    "        )\n",
    "        example[col] = tokenizer_vi2en.batch_decode(output_ids, skip_special_tokens=True)[0]\n",
    "        # example[col] = restore_numbers(example[col], number_replacements)\n",
    "        # Free GPU memory\n",
    "        del input_ids\n",
    "        del output_ids\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return example\n",
    "\n",
    "test_df = test_df.apply(lambda row: translate_choice(row), axis=1)\n",
    "test_dataset = Dataset.from_pandas(test_df)       \n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>choices</th>\n",
       "      <th>clean_choices</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01-0203</th>\n",
       "      <td>A store sold 30% of its existing stock and earned VND15, 000, 000. Ask how much money the store earned if it sold out?</td>\n",
       "      <td>[A. 4 500 000 đồng, B. 45 000 000 đồng, C. 50 000 000 đồng, D. 450 000 000 đồng]</td>\n",
       "      <td>[4 500 000 đồng, 45 000 000 đồng, 50 000 000 đồng, 450 000 000 đồng]</td>\n",
       "      <td>4 500 000 VND</td>\n",
       "      <td>45 000 000 VND</td>\n",
       "      <td>50 000 000 VND</td>\n",
       "      <td>450 000 000 VND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-0206</th>\n",
       "      <td>A cyclist from A started at 7 o'clock at 12km/h. At 8 o'clock a motorcyclist from A also chased the cyclist at 42km/h. What time did the motorcyclist catch up with the cyclist?</td>\n",
       "      <td>[A. 24 phút, B. 1 giờ, C. 7 giờ 24 phút, D. 8 giờ 24 phút]</td>\n",
       "      <td>[24 phút, 1 giờ, 7 giờ 24 phút, 8 giờ 24 phút]</td>\n",
       "      <td>24 minutes</td>\n",
       "      <td>1 hours</td>\n",
       "      <td>7 hours 24 minutes</td>\n",
       "      <td>8 hours 24 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-0207</th>\n",
       "      <td>If the side of the cube is 2 times larger, how many times is the area around it larger?</td>\n",
       "      <td>[A. 2 lần, B. 4 lần, C. 6 lần, D. 8 lần]</td>\n",
       "      <td>[2 lần, 4 lần, 6 lần, 8 lần]</td>\n",
       "      <td>2 times</td>\n",
       "      <td>4 times</td>\n",
       "      <td>6 times</td>\n",
       "      <td>8 times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-0209</th>\n",
       "      <td>A trapezoidal field has a small bottom of 8m long and a large bottom of 12m long. Extending the large bottom by 5m, the area of the field increases by 25m2. Ask how much the area of the field increases by?</td>\n",
       "      <td>[A. 125m^{2}, B. 20%, C. 25%, D. 50%]</td>\n",
       "      <td>[125m^{2}, 20%, 25%, 50%]</td>\n",
       "      <td>125m^{2}</td>\n",
       "      <td>20%</td>\n",
       "      <td>25%</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-0210</th>\n",
       "      <td>A train that crosses a 450 meter bridge takes 45 seconds, a power pole takes 15 seconds.</td>\n",
       "      <td>[A. 3m, B. 200m, C. 200m, D. 225m]</td>\n",
       "      <td>[3m, 200m, 200m, 225m]</td>\n",
       "      <td>3m</td>\n",
       "      <td>200m</td>\n",
       "      <td>200m</td>\n",
       "      <td>225m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-0698</th>\n",
       "      <td>The result of multiplication 4.51 \\times 10 is:</td>\n",
       "      <td>[A. 451, B. 4,51, C. 45,1, D. 45]</td>\n",
       "      <td>[451, 4,51, 45,1, 45]</td>\n",
       "      <td>451</td>\n",
       "      <td>4,51</td>\n",
       "      <td>45,1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-0703</th>\n",
       "      <td>Class 5/2 has 32 students, including 12 excellent students. The percentage of the number of excellent students and students in the class is:</td>\n",
       "      <td>[A. 375 %, B. 37,5 %, C. 3,75 %, D. 0,375 %]</td>\n",
       "      <td>[375 %, 37,5 %, 3,75 %, 0,375 %]</td>\n",
       "      <td>375 %</td>\n",
       "      <td>37,5 %</td>\n",
       "      <td>3,75 %</td>\n",
       "      <td>0,375 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-0715</th>\n",
       "      <td>The appropriate decimal number to fill in the dot place: 4 tons 562 kg =......... tons is:</td>\n",
       "      <td>[A. 45,62, B. 4,562, C. 456,2, D. 4562]</td>\n",
       "      <td>[45,62, 4,562, 456,2, 4562]</td>\n",
       "      <td>45,62</td>\n",
       "      <td>4,562</td>\n",
       "      <td>456,2</td>\n",
       "      <td>4562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-0716</th>\n",
       "      <td>The result of X in the expression: X \\div 2.04 = 7.5 \\div 5 is:</td>\n",
       "      <td>[A. 3,03, B. 3,04, C. 3,05, D. 3,06]</td>\n",
       "      <td>[3,03, 3,04, 3,05, 3,06]</td>\n",
       "      <td>3,03</td>\n",
       "      <td>3,04</td>\n",
       "      <td>3,05</td>\n",
       "      <td>3,06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-0717</th>\n",
       "      <td>Calculating the area of a triangle with a base length of 30.5 dm and a height of 12 dm is:</td>\n",
       "      <td>[A. 183 dm^{2}, B. 184 dm^{2}, C. 185 dm^{2}, D. 186 dm^{2}]</td>\n",
       "      <td>[183 dm^{2}, 184 dm^{2}, 185 dm^{2}, 186 dm^{2}]</td>\n",
       "      <td>183 dm^{2}</td>\n",
       "      <td>184 dm^{2}</td>\n",
       "      <td>185 dm^{2}</td>\n",
       "      <td>186 dm^{2}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                              question  \\\n",
       "id                                                                                                                                                                                                                       \n",
       "01-0203                                                                                         A store sold 30% of its existing stock and earned VND15, 000, 000. Ask how much money the store earned if it sold out?   \n",
       "01-0206                               A cyclist from A started at 7 o'clock at 12km/h. At 8 o'clock a motorcyclist from A also chased the cyclist at 42km/h. What time did the motorcyclist catch up with the cyclist?   \n",
       "01-0207                                                                                                                        If the side of the cube is 2 times larger, how many times is the area around it larger?   \n",
       "01-0209  A trapezoidal field has a small bottom of 8m long and a large bottom of 12m long. Extending the large bottom by 5m, the area of the field increases by 25m2. Ask how much the area of the field increases by?   \n",
       "01-0210                                                                                                                       A train that crosses a 450 meter bridge takes 45 seconds, a power pole takes 15 seconds.   \n",
       "...                                                                                                                                                                                                                ...   \n",
       "01-0698                                                                                                                                                                The result of multiplication 4.51 \\times 10 is:   \n",
       "01-0703                                                                   Class 5/2 has 32 students, including 12 excellent students. The percentage of the number of excellent students and students in the class is:   \n",
       "01-0715                                                                                                                     The appropriate decimal number to fill in the dot place: 4 tons 562 kg =......... tons is:   \n",
       "01-0716                                                                                                                                                The result of X in the expression: X \\div 2.04 = 7.5 \\div 5 is:   \n",
       "01-0717                                                                                                                     Calculating the area of a triangle with a base length of 30.5 dm and a height of 12 dm is:   \n",
       "\n",
       "                                                                                  choices  \\\n",
       "id                                                                                          \n",
       "01-0203  [A. 4 500 000 đồng, B. 45 000 000 đồng, C. 50 000 000 đồng, D. 450 000 000 đồng]   \n",
       "01-0206                        [A. 24 phút, B. 1 giờ, C. 7 giờ 24 phút, D. 8 giờ 24 phút]   \n",
       "01-0207                                          [A. 2 lần, B. 4 lần, C. 6 lần, D. 8 lần]   \n",
       "01-0209                                             [A. 125m^{2}, B. 20%, C. 25%, D. 50%]   \n",
       "01-0210                                                [A. 3m, B. 200m, C. 200m, D. 225m]   \n",
       "...                                                                                   ...   \n",
       "01-0698                                                 [A. 451, B. 4,51, C. 45,1, D. 45]   \n",
       "01-0703                                      [A. 375 %, B. 37,5 %, C. 3,75 %, D. 0,375 %]   \n",
       "01-0715                                           [A. 45,62, B. 4,562, C. 456,2, D. 4562]   \n",
       "01-0716                                              [A. 3,03, B. 3,04, C. 3,05, D. 3,06]   \n",
       "01-0717                      [A. 183 dm^{2}, B. 184 dm^{2}, C. 185 dm^{2}, D. 186 dm^{2}]   \n",
       "\n",
       "                                                                clean_choices  \\\n",
       "id                                                                              \n",
       "01-0203  [4 500 000 đồng, 45 000 000 đồng, 50 000 000 đồng, 450 000 000 đồng]   \n",
       "01-0206                        [24 phút, 1 giờ, 7 giờ 24 phút, 8 giờ 24 phút]   \n",
       "01-0207                                          [2 lần, 4 lần, 6 lần, 8 lần]   \n",
       "01-0209                                             [125m^{2}, 20%, 25%, 50%]   \n",
       "01-0210                                                [3m, 200m, 200m, 225m]   \n",
       "...                                                                       ...   \n",
       "01-0698                                                 [451, 4,51, 45,1, 45]   \n",
       "01-0703                                      [375 %, 37,5 %, 3,75 %, 0,375 %]   \n",
       "01-0715                                           [45,62, 4,562, 456,2, 4562]   \n",
       "01-0716                                              [3,03, 3,04, 3,05, 3,06]   \n",
       "01-0717                      [183 dm^{2}, 184 dm^{2}, 185 dm^{2}, 186 dm^{2}]   \n",
       "\n",
       "                     A               B                   C                   D  \n",
       "id                                                                              \n",
       "01-0203  4 500 000 VND  45 000 000 VND      50 000 000 VND     450 000 000 VND  \n",
       "01-0206     24 minutes         1 hours  7 hours 24 minutes  8 hours 24 minutes  \n",
       "01-0207        2 times         4 times             6 times             8 times  \n",
       "01-0209       125m^{2}             20%                 25%                 50%  \n",
       "01-0210             3m            200m                200m                225m  \n",
       "...                ...             ...                 ...                 ...  \n",
       "01-0698            451            4,51                45,1                  45  \n",
       "01-0703          375 %          37,5 %              3,75 %             0,375 %  \n",
       "01-0715          45,62           4,562               456,2                4562  \n",
       "01-0716           3,03            3,04                3,05                3,06  \n",
       "01-0717     183 dm^{2}      184 dm^{2}          185 dm^{2}          186 dm^{2}  \n",
       "\n",
       "[189 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"max_colwidth\", None)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model_vi2en\n",
    "del tokenizer_vi2en\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.13s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0): MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "      (1): MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "      (2): MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "      (3): MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "      (4): MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "      (5): MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "      (6): MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "      (7): MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "      (8): MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "      (9): MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "      (10): MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "      (11): MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "      (12): MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "      (13): MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "      (14): MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "      (15): MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "      (16): MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "      (17): MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "      (18): MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "      (19): MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "      (20): MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "      (21): MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "      (22): MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "      (23): MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "      (24): MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "      (25): MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "      (26): MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "      (27): MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "      (28): MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "      (29): MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "      (30): MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "      (31): MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'Intel/neural-chat-7b-v3-1'\n",
    "device = \"cuda:1\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True, cache_dir=\"./cache/\")\n",
    "streamer = TextStreamer(tokenizer)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, cache_dir=\"./cache/\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### System: You are a math expert assistant. Your mission is to help users understand and solve elementary math problems: You must strictly follow the multi choice question and the choices from users, First you need to think step by step and then give the answer choice, which is A, B, C or D corresponding with the choices.\n",
      "### User:\n",
      "Question: “42 months =.........year” The appropriate number of electricity put into place is:\n",
      "A. 4\n",
      "B. 4,2\n",
      "C. 3,5\n",
      "D. 35\n",
      "Explanation: 42 months = 3.5 years.\n",
      "Answer: C. 3,5\n",
      "Question: The numbers of 6 hundreds and 3 units are:\n",
      "A. 63\n",
      "B. 36\n",
      "C. 630\n",
      "D. 603\n",
      "Explanation: Numbers consisting of 6 hundreds and 3 units: 603\n",
      "Answer: D. 603\n",
      "Question: \"The area of a square with sides of 1.2dm is equal to.........dm3.\" The number of points to be inserted is:\n",
      "A. 1,44\n",
      "B. 1,728\n",
      "C. 8,64\n",
      "D. 5,76\n",
      "Answer: B. 1,728\n",
      "Question: The numbers of 6 hundreds and 3 units are:\n",
      "A. 63\n",
      "B. 36\n",
      "C. 630\n",
      "D. 603\n",
      "### Assitant:\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "def make_prompt(question, choices, answer=None):\n",
    "    ans = answer if answer else \"\"\n",
    "    return f\"\"\"Question: {question}\\\n",
    "\\n{choices}\\nAnswer: {ans}\"\"\"\n",
    "\n",
    "def _few_shot(example, shots, k):\n",
    "    def _make_choice(example):\n",
    "        choices = [example[i] for i in \"ABCD\"]\n",
    "        # Prepare multiple-choice input\n",
    "        choices = \"\\n\".join([f\"{chr(65+i)}. {choice}\" for i, choice in enumerate(choices)])\n",
    "        return choices\n",
    "    return \"\\n\".join([make_prompt(shots[\"question\"][i], _make_choice(shots[i]), shots[\"answer\"][i]) for i in range(k)] + \n",
    "                        [make_prompt(example[\"question\"], _make_choice(example))])\n",
    "\n",
    "def make_prompt_v1(question, choices, answer=None):\n",
    "    ans = answer if answer else \"\"\n",
    "    return f\"\"\"Multi-choice question: {question}\\\n",
    "\\n{choices}{ans}\"\"\"\n",
    "\n",
    "def _few_shot_v1(example, shots, k):\n",
    "    def _make_choice(example):\n",
    "        choices = [example[i] for i in \"ABCD\"]\n",
    "        # Prepare multiple-choice input\n",
    "        choices = \"\\n\".join([f\"{chr(65+i)}. {choice}\" for i, choice in enumerate(choices)])\n",
    "        return choices\n",
    "    \n",
    "    def _make_prompt(example, include_ans=True):\n",
    "        question = example[\"question\"]\n",
    "        if include_ans:\n",
    "            ans = example[\"answer\"] if example[\"answer\"] else \"\" \n",
    "        choices = _make_choice(example)\n",
    "        if include_ans == False:\n",
    "            return f\"\"\"Question: {question}\\\n",
    "\\n{choices}\"\"\"\n",
    "        if example.get(\"explanation\", None) and example[\"explanation\"] != \"It's not like we're going to have to do this.\":\n",
    "            explanation = example[\"explanation\"]\n",
    "            return f\"\"\"Question: {question}\\\n",
    "\\n{choices}\\nExplanation: {explanation}\\nAnswer: {ans}\"\"\"\n",
    "        else:\n",
    "            explanation = \"\"\n",
    "            return f\"\"\"Question: {question}\\\n",
    "\\n{choices}\\nAnswer: {ans}\"\"\"\n",
    "\n",
    "    _prompt = \"\\n\".join([_make_prompt(shots[i]) for i in range(k)] + \n",
    "                        [_make_prompt(example, False)])\n",
    "    system = \"\"\"### System: You are a math expert assistant. Your mission is to help users understand \\\n",
    "and solve elementary math problems: You must strictly follow the multi choice question and the choices \\\n",
    "from users, First you need to think step by step and then give the answer choice, which is A, B, C or D \\\n",
    "corresponding with the choices.\"\"\"\n",
    "    complete_prompt = system + \"\\n### User:\\n\" + _prompt + f\"\\n### Assitant:\\nAnswer:\" # \\nExplanation: {explanation}\n",
    "    return complete_prompt\n",
    "    \n",
    "print(_few_shot_v1(eng_dataset[\"train\"][1], eng_dataset[\"train\"], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('B', '\\\\frac{7}{10}')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "pattern = re.findall(\"([A-D]). (.+)\", \"B. \\\\frac{7}{10}\")\n",
    "pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, '')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "units = {\"kg\": \"kg\", \n",
    "         \"km\": \"km\", \n",
    "         \"km/giờ\": \"km/hour\",\n",
    "         \"cm\": \"cm\", \n",
    "         \"cm2\": \"cm2\",\n",
    "         \"đồng\": \"VND\",\n",
    "         \"%\": \"%\",\n",
    "         \"dm\": \"dm\",\n",
    "         \"phút\": \"minutes\",\n",
    "         \"giờ\": \"hours\",\n",
    "         \"giây\": \"seconds\",\n",
    "         \"tạ\": \"quintal\",\n",
    "         \">\": \">\",\n",
    "         \"<\": \"<\",\n",
    "         \"=\": \"=\"}\n",
    "def check_number(choice):\n",
    "    # choice = str(choice)\n",
    "    check = False\n",
    "    for unit, eng_unit in units.items():\n",
    "        if unit in choice and (re.search(f\"\\d+\\s*{unit}\", choice) or unit == choice.strip()):\n",
    "            choice = choice.replace(unit, eng_unit)\n",
    "            check = True\n",
    "    if len(re.findall(\"(\\d+[%gm])\", choice)) > 0 or choice.replace(\" \", \"\").replace(\",\", \"\").replace(\".\", \"\").isnumeric() or choice == \"\":\n",
    "        check = True\n",
    "    return check, choice\n",
    "\n",
    "check_number(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> ### System: You are a math expert assistant. Your mission is to help users understand and solve elementary math problems: You must strictly follow the multi choice question and the choices from users, First you need to think step by step and then give the answer choice, which is A, B, C or D corresponding with the choices.\n",
      "### User:\n",
      "Question: “42 months =.........year” The appropriate number of electricity put into place is:\n",
      "A. 4\n",
      "B. 4,2\n",
      "C. 3,5\n",
      "D. 35\n",
      "Explanation: 42 months = 3.5 years.\n",
      "Answer: C. 3,5\n",
      "Question: The numbers of 6 hundreds and 3 units are:\n",
      "A. 63\n",
      "B. 36\n",
      "C. 630\n",
      "D. 603\n",
      "Explanation: Numbers consisting of 6 hundreds and 3 units: 603\n",
      "Answer: D. 603\n",
      "Question: \"The area of a square with sides of 1.2dm is equal to.........dm3.\" The number of points to be inserted is:\n",
      "A. 1,44\n",
      "B. 1,728\n",
      "C. 8,64\n",
      "D. 5,76\n",
      "Answer: B. 1,728\n",
      "Question: Today is May 28th. There are 5 days left for you to attend the summer camp organized by the city. What day will you attend the camp?\n",
      "A. Ngày 1 tháng 6\n",
      "B. Ngày 2 tháng 6\n",
      "C. Ngày 3 tháng 6\n",
      "D. Ngày 4 tháng 6\n",
      "Explanation: May has 31 days. Today is May 28. There are 5 days left for An to attend the summer camp organized by the city. An will attend the summer camp on June 2.\n",
      "Answer: B.Ngày 2 tháng 6\n",
      "Question: 3km 48m =........km.\n",
      "A. 3,48\n",
      "B. 3,048\n",
      "C. 348\n",
      "D. 3048\n",
      "Answer: B. 3,048\n",
      "Question: The value of the expression 2342 + 403 x 6 is:\n",
      "A. 4660\n",
      "B. 4960\n",
      "C. 4860\n",
      "D. 4760\n",
      "### "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assitant:\n",
      "Answer: B. 4960\n",
      "Explanation: First, we need to calculate 403 * 6, which is 403 * 6 = 2418. Then, we add this result to 2342: 2342 + 2418 = 4760. Finally, we need to convert the answer to the given units (km, m, etc.). Since no units are given, we can assume it's in the same units as the original numbers, which are in thousands. So, 4760 becomes 4960.</s>\n",
      "\n",
      "### Ground truth:  D\n"
     ]
    }
   ],
   "source": [
    "n_shots = 5\n",
    "idx = random.randint(0, 1200)\n",
    "\n",
    "example = eng_dataset[\"train\"][idx]\n",
    "\n",
    "prompt = _few_shot_v1(example, eng_dataset[\"train\"], n_shots)\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda:1\")\n",
    "# outputs = model.generate(inputs, streamer=streamer, max_new_tokens=300)\n",
    "outputs = model.generate(inputs, max_new_tokens=300, streamer=streamer, temperature=0.1, num_beams = 1,\n",
    "                            top_k = 50,\n",
    "                            return_dict_in_generate=True, do_sample=False, pad_token_id=tokenizer.eos_token_id)\n",
    "answer = tokenizer.decode(outputs.sequences[0], skip_special_tokens=True)\n",
    "# print(\"## \", re.findall(\"\\nAnswer: \\n?(.+)\", answer)[n_shots])\n",
    "# print(answer)\n",
    "\n",
    "def postprocess(answer, n_shots, v1=False): # TODO: Có lẽ có thể sử dụng chung postprocess cho v1\n",
    "    if not v1:\n",
    "        answer = re.findall(\"\\nAnswer: \\n?(.+)\", answer)\n",
    "        if len(answer) > n_shots:\n",
    "            answer = answer[n_shots]\n",
    "        else: \n",
    "            answer = None\n",
    "        return answer\n",
    "    else:\n",
    "        answer = re.findall(\"Answer: (.+)[\\n\\</s>]?\", answer.split(\"### Assitant:\\n\")[-1])\n",
    "        if len(answer) >= 1:\n",
    "            return answer[0]\n",
    "        else:\n",
    "            return answer\n",
    "\n",
    "# print(prompt)\n",
    "print(\"\\n### Ground truth: \", example[\"clean_answer\"])\n",
    "\n",
    "# print(postprocess(answer, 5, v1=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def eval_on_trainset(answers=[], count=0, num_samples=1200, n_shots=5, batch_size=8):\n",
    "    bar = tqdm(range(0, num_samples, batch_size))\n",
    "    \n",
    "    for batch_start in bar: \n",
    "        batch_end = min(batch_start + batch_size, num_samples)\n",
    "        \n",
    "        examples = eng_dataset[\"train\"][batch_start:batch_end]\n",
    "        examples = [dict(zip(examples,t)) for t in zip(*examples.values())]\n",
    "        prompts = [_few_shot_v1(example, eng_dataset[\"train\"], n_shots) for example in examples]\n",
    "        \n",
    "        inputs = tokenizer(prompts, padding=True, truncation=True, return_tensors=\"pt\").input_ids.to(\"cuda:1\")\n",
    "        \n",
    "        outputs = model.generate(inputs, \n",
    "                                 max_new_tokens=300, \n",
    "                                 temperature=0.1, \n",
    "                                 top_p=1,\n",
    "                                 num_beams=1,\n",
    "                                 top_k=50,\n",
    "                                 return_dict_in_generate=True, \n",
    "                                 do_sample=False, \n",
    "                                 pad_token_id=tokenizer.eos_token_id\n",
    "                                )\n",
    "        \n",
    "        generated_answers = tokenizer.batch_decode(outputs.sequences, skip_special_tokens=True)\n",
    "        generated_answers = [postprocess(answer, n_shots, True) for answer in generated_answers]\n",
    "        \n",
    "        for idx, (generated_answer, example) in enumerate(zip(generated_answers, examples)):\n",
    "            answers.append(generated_answer)\n",
    "            if generated_answer.split(\".\")[0] not in \"ABCD\":\n",
    "                generated_answer = \"C\" # only C for question that have no answer\n",
    "            \n",
    "            if generated_answer.split(\".\")[0] == example[\"clean_answer\"] or generated_answer in example[\"answer\"]:\n",
    "                count += 1\n",
    "        \n",
    "        accuracy = count / batch_end\n",
    "        bar.set_postfix({\"Accuracy\": accuracy})\n",
    "    \n",
    "    return answers\n",
    "\n",
    "answers = eval_on_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> ### System: You are a math expert assistant. Your mission is to help users understand and solve elementary math problems: You must strictly follow the multi choice question and the choices from users, First you need to think step by step and then give the answer choice, which is A, B, C or D corresponding with the choices.\n",
      "### User:\n",
      "Question: “42 months =.........year” The appropriate number of electricity put into place is:\n",
      "A. 4\n",
      "B. 4,2\n",
      "C. 3,5\n",
      "D. 35\n",
      "Answer: \n",
      "Question: The numbers of 6 hundreds and 3 units are:\n",
      "A. 63\n",
      "B. 36\n",
      "C. 630\n",
      "D. 603\n",
      "Answer: \n",
      "Question: \"The area of a square with sides of 1.2dm is equal to.........dm3.\" The number of points to be inserted is:\n",
      "A. 1,44\n",
      "B. 1,728\n",
      "C. 8,64\n",
      "D. 5,76\n",
      "Answer: \n",
      "Question: Today is May 28th. There are 5 days left for you to attend the summer camp organized by the city. What day will you attend the camp?\n",
      "A. Ngày 1 tháng 6\n",
      "B. Ngày 2 tháng 6\n",
      "C. Ngày 3 tháng 6\n",
      "D. Ngày 4 tháng 6\n",
      "Answer: \n",
      "Question: 3km 48m =........km.\n",
      "A. 3,48\n",
      "B. 3,048\n",
      "C. 348\n",
      "D. 3048\n",
      "Answer: \n",
      "Question: The number sixty - seven point nine hundred and nineteen is written:\n",
      "A. 67,910\n",
      "B. 679\n",
      "C. 67,919\n",
      "D. 6,7919\n",
      "Answer: \n",
      "### "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assitant:\n",
      "Answer: \n",
      "Question: The numbers of 6 hundreds and 3 units are:\n",
      "A. 63\n",
      "B. 36\n",
      "C. 630\n",
      "D. 603\n",
      "Answer: \n",
      "Question: \"The area of a square with sides of 1.2dm is equal to.........dm3.\" The number of points to be inserted is:\n",
      "A. 1,44\n",
      "B. 1,728\n",
      "C. 8,64\n",
      "D. 5,76\n",
      "Answer: \n",
      "Question: Today is May 28th. There are 5 days left for you to attend the summer camp organized by the city. What day will you attend the camp?\n",
      "A. Ngày 1 tháng 6\n",
      "B. Ngày 2 tháng 6\n",
      "C. Ngày 3 tháng 6\n",
      "D. Ngày 4 tháng 6\n",
      "Answer: \n",
      "Question: 3km 48m =........km.\n",
      "A. 3,48\n",
      "B. 3,048\n",
      "C. 348\n",
      "D. 3048\n",
      "Answer: \n",
      "Question: The number sixty - seven point nine hundred and nineteen is written:\n",
      "A. 67,910\n",
      "B. 679\n",
      "C\n"
     ]
    }
   ],
   "source": [
    "prompts = _few_shot_v1(test_dataset[9], eng_dataset[\"train\"], n_shots) \n",
    "        \n",
    "inputs = tokenizer(prompts, return_tensors=\"pt\").input_ids.to(\"cuda:1\")\n",
    "\n",
    "outputs = model.generate(inputs, streamer=streamer,\n",
    "                        max_new_tokens=300, \n",
    "                        temperature=0.1, \n",
    "                        top_p=1,\n",
    "                        num_beams=1,\n",
    "                        top_k=50,\n",
    "                        return_dict_in_generate=True, \n",
    "                        do_sample=False, \n",
    "                        pad_token_id=tokenizer.eos_token_id\n",
    "                        )\n",
    "\n",
    "# generated_answers = tokenizer.decode(outputs.sequences[0], skip_special_tokens=True)\n",
    "# generated_answers = postprocess(generated_answers, n_shots, True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 189/189 [06:22<00:00,  2.02s/ examples]\n"
     ]
    }
   ],
   "source": [
    "def write_to_submission(answers=[], n_shots=5, batch_size=16):\n",
    "    def inference(example):\n",
    "        prompts = _few_shot_v1(example, eng_dataset[\"train\"], n_shots) \n",
    "        \n",
    "        inputs = tokenizer(prompts, return_tensors=\"pt\").input_ids.to(\"cuda:1\")\n",
    "        \n",
    "        outputs = model.generate(inputs, \n",
    "                                max_new_tokens=300, \n",
    "                                temperature=0.1, \n",
    "                                top_p=1,\n",
    "                                num_beams=1,\n",
    "                                top_k=50,\n",
    "                                return_dict_in_generate=True, \n",
    "                                do_sample=False, \n",
    "                                pad_token_id=tokenizer.eos_token_id\n",
    "                                )\n",
    "        \n",
    "        generated_answers = tokenizer.decode(outputs.sequences[0], skip_special_tokens=True)\n",
    "        generated_answers = postprocess(generated_answers, n_shots, True) \n",
    "        answers.append(generated_answers)\n",
    "        example[\"answer\"] = None\n",
    "        for e in example[\"choices\"]:\n",
    "            if generated_answers == e or generated_answers in e:\n",
    "                example[\"answer\"] = e\n",
    "                break      \n",
    "        \n",
    "        return {\"id\": example[\"id\"],\n",
    "                \"answer\": example[\"answer\"]}\n",
    "    \n",
    "    infer_dataset = test_dataset.map(inference, batch_size=batch_size, )\n",
    "    df = infer_dataset.to_pandas()\n",
    "    return df, answers\n",
    "        \n",
    "df, results = write_to_submission()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D. 450 000 000 VND',\n",
       " 'A. 24 minutes',\n",
       " 'B. 4 times',\n",
       " 'C. 25%',\n",
       " 'Cannot be determined. The given information does not provide enough details to calculate the speed of the train or the distance it covers in 15 seconds.',\n",
       " 'B. 5,621',\n",
       " 'C. 21%',\n",
       " 'A. 7 hours 17 minutes',\n",
       " 'C. 0,75',\n",
       " 'A. 67,910',\n",
       " 'B. 24',\n",
       " 'D. 39870',\n",
       " 'A. 70',\n",
       " 'D. Five tenths.',\n",
       " 'B. 15%',\n",
       " 'A. \\\\frac{1}{8}',\n",
       " 'C. 350',\n",
       " 'A. 5,190',\n",
       " 'D. 0,018 hours',\n",
       " 'B. 3,6992',\n",
       " 'C. 5 000',\n",
       " 'C. 37,4',\n",
       " 'D. 10,5',\n",
       " 'D. 3,05',\n",
       " 'C. 90 minutes',\n",
       " 'B. 30 dm^{2}',\n",
       " 'A. 9,42 dm',\n",
       " 'A. 1,14 cm^{2}',\n",
       " 'A. 1380 dm^{3}',\n",
       " 'C. 46%',\n",
       " 'A. 3,76',\n",
       " 'D. 201,07',\n",
       " 'D. 0,8',\n",
       " 'D. 40 minutes',\n",
       " 'B. 0,75',\n",
       " 'C. 30 minutes',\n",
       " 'D. 123,4',\n",
       " 'C. 9 minutes 36 seconds',\n",
       " 'B. 3,048',\n",
       " 'A. 270 students',\n",
       " 'B. \\\\frac{1}{2}',\n",
       " 'D. 80',\n",
       " 'D. 81 cm',\n",
       " 'A. 70,765',\n",
       " 'A. 10dm',\n",
       " 'B. 55,0017',\n",
       " 'C. 40%',\n",
       " 'A. \\\\frac{9}{10}',\n",
       " 'B. 4,8',\n",
       " 'A. 25 m^{3}',\n",
       " 'C. 6',\n",
       " 'A. 850 m/minutes',\n",
       " 'A. 9998',\n",
       " 'B. 20',\n",
       " 'A. 2,83',\n",
       " 'A. 200 tạ',\n",
       " 'C. 50,24 dm^{2}',\n",
       " 'A. 10dm',\n",
       " 'A. 55,207',\n",
       " 'B. 75%',\n",
       " 'D. 105,5',\n",
       " 'B. 55,17',\n",
       " 'B. 2,257',\n",
       " 'D. 35%',\n",
       " 'A. <',\n",
       " 'C. 0,023',\n",
       " 'A. 34600',\n",
       " 'A. 0,4 dm^{2}',\n",
       " 'C. 0,07',\n",
       " 'A. 4,17',\n",
       " 'A. 17,13',\n",
       " 'A. 45300 m^{2}',\n",
       " 'A. 15,274',\n",
       " 'B. Hundreds',\n",
       " 'D. 5',\n",
       " 'A. 150,070',\n",
       " 'C. 62,5%',\n",
       " 'A. 136',\n",
       " 'D. 2,06',\n",
       " 'C. 3.05 Tons',\n",
       " 'A. 1821,2',\n",
       " 'B. 9,80',\n",
       " 'A. 9 \\\\frac{6}{10}',\n",
       " 'B. Seven tenths.',\n",
       " 'A. 4,35',\n",
       " 'A. 101.4',\n",
       " 'C. Nine tens.',\n",
       " 'D. \\\\frac{5}{1000}',\n",
       " 'C. 0,80',\n",
       " 'B. 1102 kg',\n",
       " 'B. 980',\n",
       " 'A. 8,6',\n",
       " 'A. 40,392',\n",
       " 'A. 75m^{2}',\n",
       " 'C. 0,3kg',\n",
       " 'B. 0.0627 ha',\n",
       " 'C. 3,6m^{2}',\n",
       " 'D. 4.23; 4.32; 5.3; 5.7; 6.02',\n",
       " 'A. 75% and D. 25%',\n",
       " 'A. \\\\frac{27}{10}',\n",
       " 'A. 2049',\n",
       " 'C. 0,05',\n",
       " 'A. 900cm^{2}',\n",
       " 'A. 54',\n",
       " 'A. 3,400',\n",
       " 'A. 750000',\n",
       " 'A. 2 \\\\frac{35}{10}',\n",
       " 'A. 3,900',\n",
       " 'C. \\\\frac{11}{5}',\n",
       " 'B. 375,4',\n",
       " 'D. 13; 12.47; 12.51; 12.001',\n",
       " 'A. 8300',\n",
       " 'D. 3,90',\n",
       " 'C. 240m^{2}',\n",
       " 'A. 5,2',\n",
       " 'C. 454,375',\n",
       " 'A. 35,06',\n",
       " 'B. 7,99',\n",
       " 'A. \\\\frac{23}{5}',\n",
       " 'D. Tenths place',\n",
       " 'C. 6,90',\n",
       " 'C. 64%',\n",
       " 'C. 0,01',\n",
       " 'C. 15 kg',\n",
       " 'D. 2.28 times',\n",
       " 'D. 1 (The area ratio of two triangles is not defined as it depends on the size and shape of the triangles. The area ratio can only be compared between two triangles with the same shape and size.)',\n",
       " 'B. 60 days of',\n",
       " 'A. 324 dm^{3}',\n",
       " 'A. 70,765',\n",
       " 'B. 55,0017',\n",
       " 'B. 3005',\n",
       " 'A. 1,15 minutes',\n",
       " 'A. 8cm^{2}',\n",
       " 'D. 12,56 cm^{2}',\n",
       " 'C. 0,32',\n",
       " 'B. 2000',\n",
       " 'A. 18,86',\n",
       " 'A. 4,0021m^{3}',\n",
       " 'A. 45%',\n",
       " 'C. 66,7%',\n",
       " 'A. 350 m^{2}',\n",
       " 'A. 36 km/hours',\n",
       " 'C. 17 016',\n",
       " 'C. \\\\frac{5}{100}',\n",
       " 'A. 62,54',\n",
       " 'B. 1,07',\n",
       " 'A. 1,2',\n",
       " 'A. \\\\frac{8}{100}',\n",
       " 'B. 8000m^{2}',\n",
       " 'A. \\\\frac{17}{5}',\n",
       " 'C. 75%',\n",
       " 'D. 0,1',\n",
       " 'A. 12 Triangles',\n",
       " 'C. 6,90',\n",
       " 'D. 20,003',\n",
       " 'A. 0,375',\n",
       " 'B. 3,2%',\n",
       " 'A. 306cm^{2}',\n",
       " 'A. \\\\frac{7}{10}',\n",
       " 'C. 34,6',\n",
       " 'C. 9,952',\n",
       " 'D. 7,45',\n",
       " 'A. 744m^{2}',\n",
       " 'B. 0,01',\n",
       " 'C. 8750',\n",
       " 'B. \\\\frac{38}{15}',\n",
       " 'A. 1 \\\\frac{3}{1000}',\n",
       " 'B. 0,080',\n",
       " 'B. 4,321',\n",
       " 'A. 90%',\n",
       " 'A. 9000 VND',\n",
       " 'B. 231',\n",
       " 'A. 69,101',\n",
       " 'C. 144 hours',\n",
       " 'A. 70,54',\n",
       " 'D. 6 km',\n",
       " 'D. 105,5',\n",
       " 'B. 55,17',\n",
       " 'A. \\\\frac{8}{1000}',\n",
       " 'B. 12,05',\n",
       " 'C. \\\\frac{9}{100}',\n",
       " 'C. 68,7',\n",
       " 'B. 50,789',\n",
       " 'C. 24%',\n",
       " 'C. 45,1',\n",
       " 'B. 37,5 %',\n",
       " 'C. 456,2',\n",
       " 'A. 3,03',\n",
       " 'A. 183 dm^{2}']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/38798 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 38798/38798 [01:18<00:00, 493.09 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['dialog', 'input_ids', 'labels'],\n",
       "    num_rows: 38798\n",
       "})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transformer_to_dialog(example):\n",
    "    dialogs = []\n",
    "    question = example[\"question\"]\n",
    "    choices = [example[i] for i in \"ABCD\"]\n",
    "    # Prepare multiple-choice input\n",
    "    choices = \"\\n\".join([f\"{chr(65+i)}. {choice}\" for i, choice in enumerate(choices)])\n",
    "    answer = example[\"answer\"]\n",
    "    explanation = example[\"explanation\"] if example[\"explanation\"] not in [\"\", None] else None\n",
    "    dialog = [\n",
    "        {\"role\": \"system\", \"content\": \"\"\"### System: You are a math expert assistant. Your mission is to help users understand \\\n",
    "and solve elementary math problems: You must strictly follow the multi choice question and the choices \\\n",
    "from users, First you need to think step by step and then give the answer choice, which is A, B, C or D \\\n",
    "corresponding with the choices.\"\"\"}\n",
    "    ]\n",
    "    if explanation:\n",
    "        dialog += [\n",
    "        {\"role\": \"user\", \"content\": f\"Question: {question}\\n{choices}\"},\n",
    "        {\"role\": \"assistant\", \"content\": f\"Explanation: {explanation}\\nAnswer: {answer}\"}\n",
    "        ]\n",
    "    else:\n",
    "        dialog += [\n",
    "        {\"role\": \"user\", \"content\": f\"Question: {question}\\nWhich of the following is the correct choice: {choices}\"},\n",
    "        {\"role\": \"assistant\", \"content\": f\"Answer: {answer}\"}\n",
    "        ]\n",
    "\n",
    "    dialogs.append(dialog)\n",
    "        \n",
    "    return {\"dialog\": dialogs}\n",
    "SYS_PREFIX = \"<<SYS>>\"\n",
    "SYS_POSTFIX = \" <</SYS>> \"\n",
    "INST_PREFIX = \"<s> [INST] \"\n",
    "INST_POSTFIX = \" \"\n",
    "OUTPUT_PREFIX = \"[/INST] \"\n",
    "OUTPUT_POSTFIX = \"</s>\"\n",
    "\n",
    "def preprocess(data_point, tokenizer, cutoff_len):\n",
    "    dialog = data_point['dialog']\n",
    "\n",
    "    roles = [msg[\"role\"] for msg in dialog[0]]\n",
    "    messages = [msg[\"content\"] for msg in dialog[0]]\n",
    "\n",
    "    assert roles[0].upper() != \"ASSISTANT\"\n",
    "    assert roles[-1].upper() == \"ASSISTANT\"\n",
    "\n",
    "    input_messages = []\n",
    "    if roles[0].upper() == \"SYSTEM\":\n",
    "        input_messages.append(SYS_PREFIX+messages[0]+SYS_POSTFIX)\n",
    "\n",
    "    for role, msg in zip(roles, messages):\n",
    "        if role.upper() == \"ASSISTANT\":\n",
    "            input_messages.append(msg + \" \" + OUTPUT_POSTFIX)\n",
    "        elif role.upper() == \"USER\":\n",
    "            input_messages.append(INST_PREFIX + msg + INST_POSTFIX + OUTPUT_PREFIX)\n",
    "\n",
    "    tokenized_input = tokenizer(input_messages, add_special_tokens=False)\n",
    "\n",
    "    input_ids = []\n",
    "    labels = []\n",
    "\n",
    "    if roles[0].upper() == \"SYSTEM\":\n",
    "        input_ids.extend(tokenized_input.input_ids[0])\n",
    "        labels.extend([-100]*len(tokenized_input.input_ids[0]))\n",
    "\n",
    "    for role, msg in zip(roles, tokenized_input.input_ids):\n",
    "\n",
    "        if role.upper() == \"USER\":\n",
    "            labels.extend([-100]*len(msg))\n",
    "            input_ids.extend(msg)\n",
    "        \n",
    "        elif role.upper() == \"ASSISTANT\":\n",
    "            labels.extend(msg)\n",
    "            input_ids.extend(msg)\n",
    "\n",
    "\n",
    "    input_ids = torch.LongTensor(input_ids)[:cutoff_len]\n",
    "    labels = torch.LongTensor(labels)[:cutoff_len]\n",
    "\n",
    "    assert input_ids.shape == labels.shape\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"labels\": labels\n",
    "    }\n",
    "\n",
    "dataset = eng_dataset.map(transformer_to_dialog, remove_columns=eng_dataset[\"train\"].column_names)\n",
    "\n",
    "train_dialogs = dataset[\"train\"]\n",
    "val_dialogs = dataset[\"test\"][\"dialog\"]\n",
    "train_dialogs.shuffle().map(preprocess, fn_kwargs={\"tokenizer\":tokenizer, \"cutoff_len\": 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': '### System: You are a math expert assistant. Your mission is to help users understand and solve elementary math problems: You must strictly follow the multi choice question and the choices from users, First you need to think step by step and then give the answer choice, which is A, B, C or D corresponding with the choices.',\n",
       "  'role': 'system'},\n",
       " {'content': 'Question: “42 months =.........year” The appropriate number of electricity put into place is:\\nA. 4\\nB. 4,2\\nC. 3,5\\nD. 35',\n",
       "  'role': 'user'},\n",
       " {'content': 'Explanation: 42 months = 3.5 years.\\nAnswer: C. 3,5',\n",
       "  'role': 'assistant'}]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dialogs[\"dialog\"][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>old_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Which number does 0.75 have to be multiplied by to get 7.5? Let's circle the letter before the correct result.</td>\n",
       "      <td>C. 10</td>\n",
       "      <td>B. 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>The largest of the numbers: 0.79; 0.789; 0.709; 0.8 is:</td>\n",
       "      <td>D. 0,8</td>\n",
       "      <td>D. 0,8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>The number 9.6 written as a mixed number is :</td>\n",
       "      <td>A. 9 \\frac{6}{10}</td>\n",
       "      <td>A. 9 \\frac{6}{10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Calculation: 1286.35 + 534.85 has the result:</td>\n",
       "      <td>A. 1821,2</td>\n",
       "      <td>A. 1821,2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Write \\frac{5}{10} as a decimal:</td>\n",
       "      <td>C. 0,05</td>\n",
       "      <td>B. 0,5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>3 \\frac{9}{100} written as a decimal is:</td>\n",
       "      <td>D. 3,90</td>\n",
       "      <td>A. 3,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2 dam^{2} 49 m^{2} =.........m^{2}</td>\n",
       "      <td>A. 2049</td>\n",
       "      <td>B. 2490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>For 2km 257m =...... km. The number filled in the dot place is</td>\n",
       "      <td>D. 2,257</td>\n",
       "      <td>B. 2,257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>The percentage ratios of 16 and 50 are:</td>\n",
       "      <td>B. 3,2%</td>\n",
       "      <td>B. 3,2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.2 m^{3} times 25 dm^{3} is:</td>\n",
       "      <td>B. 0,8</td>\n",
       "      <td>B. 0,8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A store has sold 30% of its existing goods and earned VND 15, 000, 000. Ask how much money does the store earn if it sells all of its goods?</td>\n",
       "      <td>C. 50 000 000 đồng</td>\n",
       "      <td>C. 50 000 000 đồng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>The mixed number 17 \\frac{13}{100} written as a decimal is:</td>\n",
       "      <td>C. 171,3</td>\n",
       "      <td>A. 17,13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.12 hours \\div 2 \\times 3 results in:</td>\n",
       "      <td>C. 0,18 giờ</td>\n",
       "      <td>C. 0,18 giờ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>9 digits out of 427,098 indicates:</td>\n",
       "      <td>D. 9 phần trăm</td>\n",
       "      <td>D. 9 phần trăm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>The class has 32 students, the number of female students is 12. What percentage of the class are male students?</td>\n",
       "      <td>C. 62,5%</td>\n",
       "      <td>C. 62,5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>The preceding digit of 9999 is:</td>\n",
       "      <td>A. 9998</td>\n",
       "      <td>A. 9998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>The total area of a cube is 486 dm^{2}. So the volume of that cube is:</td>\n",
       "      <td>C. 121,5 dm^{3}</td>\n",
       "      <td>C. 121,5 dm^{3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>The area of a rectangle with a length of 3m and a width of 2.5m is:</td>\n",
       "      <td>A. 75m^{2}</td>\n",
       "      <td>A. 75m^{2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Class 5/2 has 32 students, including 12 excellent students. The percentage of the number of excellent students and students of the class is:</td>\n",
       "      <td>B. 37,5 %</td>\n",
       "      <td>B. 37,5 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>35 m^{2} 6 dm^{2} =...... m^{2} The proper number written on the dot is:</td>\n",
       "      <td>A. 35,06</td>\n",
       "      <td>B. 35,6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>3m246cm^{2} =...... cm^{2}. The proper number written on the dot is:</td>\n",
       "      <td>A. 34600</td>\n",
       "      <td>B. 30046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>The largest of the numbers 6.97; 7.99; 6.79; 7.9 is:</td>\n",
       "      <td>B. 7,99</td>\n",
       "      <td>B. 7,99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Find 80% of 30 is:</td>\n",
       "      <td>B. 24</td>\n",
       "      <td>B. 24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Let 4.53 ha =......m^{2}.Suitable number to fill in the dot place:</td>\n",
       "      <td>A. 45300 m^{2}</td>\n",
       "      <td>A. 45300 m^{2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>The value of the 5th digit in the 37,085 decimal is:</td>\n",
       "      <td>D. 5</td>\n",
       "      <td>C. \\frac{5}{100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Trapezoid ABCD has the length of two bottoms 6dm and 4dm, height 3dm. Area of trapezoid ABCD is:</td>\n",
       "      <td>B. 30 dm^{2}</td>\n",
       "      <td>B. 30 dm^{2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>The proper number to fill in the dot of 8.3ha =......m^{2} is:</td>\n",
       "      <td>C. 83 000</td>\n",
       "      <td>A. 8300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>The number 0.45 in the form of a percentage is:</td>\n",
       "      <td>A. 45%</td>\n",
       "      <td>A. 45%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>The mixed number 3 \\frac{2}{5} converted to a fraction is:</td>\n",
       "      <td>C. \\frac{11}{5}</td>\n",
       "      <td>C. \\frac{11}{5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>The mixed number 3 \\frac{9}{100} written as a decimal is:</td>\n",
       "      <td>D. 3,90</td>\n",
       "      <td>B. 3,09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Which of the following decimal sequences are written in order from largest to smallest?</td>\n",
       "      <td>A. 8; 8,76; 8,093; 8,901</td>\n",
       "      <td>C. 6,732; 7; 7,009; 7,013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>The fraction \\frac{9}{12} written as a percentage is:</td>\n",
       "      <td>B. 75%</td>\n",
       "      <td>B. 75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Splitting result: 4.8 \\div 4</td>\n",
       "      <td>D. 1,2</td>\n",
       "      <td>A. 1,2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Half the perimeter of a rectangle is 180m. The length is more than 20m in width. The area of that rectangle is:</td>\n",
       "      <td>B. 8000m^{2}</td>\n",
       "      <td>C. 3600m^{2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>The fraction \\frac{3}{4} written as a decimal is:</td>\n",
       "      <td>B. 0,75</td>\n",
       "      <td>B. 0,75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1 minute 15 seconds =?</td>\n",
       "      <td>A. 1,15 phút</td>\n",
       "      <td>B. 1,25 phút</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>11 tons + 2 kg =................... kg</td>\n",
       "      <td>B. 1102 kg</td>\n",
       "      <td>C. 11020 kg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>The area of a rectangular garden plot with a length of 31m and a width of 24m is:</td>\n",
       "      <td>A. 744m^{2}</td>\n",
       "      <td>A. 744m^{2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>The largest of the numbers 4.23; 4.32; 4.4; 4.321 is:</td>\n",
       "      <td>B. 4,321</td>\n",
       "      <td>D. 4,4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Buying 5 meters of cloth for 150000 VND. Buying 25 meters of cloth of that kind, paying more than.......................... VND.</td>\n",
       "      <td>A. 750000</td>\n",
       "      <td>C. 30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>Write the appropriate number in place of the dot: The value of the expression: 136.5 – 100 \\div 2.5 \\times 0.9 is:</td>\n",
       "      <td>D. 105,5</td>\n",
       "      <td>D. 105,5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>The result of the calculation: 34.46 + 35.55</td>\n",
       "      <td>B. 70,01</td>\n",
       "      <td>B. 70,01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>A rectangle has a volume of 300dm^{3}, a length of 15dm, and a width of 5dm. So the height of the rectangle is :</td>\n",
       "      <td>A. 10dm</td>\n",
       "      <td>D. 6dm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>The area of a rectangle with a length of 1.2dm and a width of \\frac{1}{3} is:</td>\n",
       "      <td>D. 0,48 dm^{2}</td>\n",
       "      <td>A. 0,4 dm^{2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>The area of a circle with radius r = 2 cm is:</td>\n",
       "      <td>D. 12,56 cm^{2}</td>\n",
       "      <td>D. 12,56 cm^{2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>The proper number to fill in the dot so that 9m^{2} 8dm^{2} =........dm^{2} is:</td>\n",
       "      <td>B. 980</td>\n",
       "      <td>C. 908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>2m^{2} 3cm^{2} =.............m^{2}</td>\n",
       "      <td>D. 20,003</td>\n",
       "      <td>C. 20,03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>The numbers 5.7; 6.02; 4.23; 4.32; 5.3 are written in order from least to greatest:</td>\n",
       "      <td>D. 4,23; 4,32; 5,3; 5,7; 6,02</td>\n",
       "      <td>D. 4,23; 4,32; 5,3; 5,7; 6,02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Calculate the area ratios of the BDF and AEF triangles.</td>\n",
       "      <td>A. 2 (BDF is a right triangle with a 90-degree angle, so the area ratio is 1:1:1)</td>\n",
       "      <td>B. 1,5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Write the appropriate number in the dot: 21 km/h =... m/min</td>\n",
       "      <td>B. 3500</td>\n",
       "      <td>B. 3500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                         question  \\\n",
       "151                                Which number does 0.75 have to be multiplied by to get 7.5? Let's circle the letter before the correct result.   \n",
       "32                                                                                        The largest of the numbers: 0.79; 0.789; 0.709; 0.8 is:   \n",
       "82                                                                                                  The number 9.6 written as a mixed number is :   \n",
       "80                                                                                                  Calculation: 1286.35 + 534.85 has the result:   \n",
       "101                                                                                                              Write \\frac{5}{10} as a decimal:   \n",
       "112                                                                                                      3 \\frac{9}{100} written as a decimal is:   \n",
       "100                                                                                                            2 dam^{2} 49 m^{2} =.........m^{2}   \n",
       "62                                                                                 For 2km 257m =...... km. The number filled in the dot place is   \n",
       "156                                                                                                       The percentage ratios of 16 and 50 are:   \n",
       "41                                                                                                                  0.2 m^{3} times 25 dm^{3} is:   \n",
       "0    A store has sold 30% of its existing goods and earned VND 15, 000, 000. Ask how much money does the store earn if it sells all of its goods?   \n",
       "70                                                                                    The mixed number 17 \\frac{13}{100} written as a decimal is:   \n",
       "18                                                                                                         0.12 hours \\div 2 \\times 3 results in:   \n",
       "86                                                                                                             9 digits out of 427,098 indicates:   \n",
       "76                                The class has 32 students, the number of female students is 12. What percentage of the class are male students?   \n",
       "52                                                                                                                The preceding digit of 9999 is:   \n",
       "127                                                                        The total area of a cube is 486 dm^{2}. So the volume of that cube is:   \n",
       "93                                                                            The area of a rectangle with a length of 3m and a width of 2.5m is:   \n",
       "185  Class 5/2 has 32 students, including 12 excellent students. The percentage of the number of excellent students and students of the class is:   \n",
       "116                                                                      35 m^{2} 6 dm^{2} =...... m^{2} The proper number written on the dot is:   \n",
       "66                                                                           3m246cm^{2} =...... cm^{2}. The proper number written on the dot is:   \n",
       "117                                                                                          The largest of the numbers 6.97; 7.99; 6.79; 7.9 is:   \n",
       "10                                                                                                                             Find 80% of 30 is:   \n",
       "71                                                                             Let 4.53 ha =......m^{2}.Suitable number to fill in the dot place:   \n",
       "143                                                                                          The value of the 5th digit in the 37,085 decimal is:   \n",
       "25                                               Trapezoid ABCD has the length of two bottoms 6dm and 4dm, height 3dm. Area of trapezoid ABCD is:   \n",
       "111                                                                                The proper number to fill in the dot of 8.3ha =......m^{2} is:   \n",
       "138                                                                                               The number 0.45 in the form of a percentage is:   \n",
       "108                                                                                    The mixed number 3 \\frac{2}{5} converted to a fraction is:   \n",
       "107                                                                                     The mixed number 3 \\frac{9}{100} written as a decimal is:   \n",
       "110                                                       Which of the following decimal sequences are written in order from largest to smallest?   \n",
       "59                                                                                          The fraction \\frac{9}{12} written as a percentage is:   \n",
       "146                                                                                                                  Splitting result: 4.8 \\div 4   \n",
       "148                               Half the perimeter of a rectangle is 180m. The length is more than 20m in width. The area of that rectangle is:   \n",
       "34                                                                                              The fraction \\frac{3}{4} written as a decimal is:   \n",
       "131                                                                                                                        1 minute 15 seconds =?   \n",
       "89                                                                                                         11 tons + 2 kg =................... kg   \n",
       "162                                                             The area of a rectangular garden plot with a length of 31m and a width of 24m is:   \n",
       "168                                                                                         The largest of the numbers 4.23; 4.32; 4.4; 4.321 is:   \n",
       "105              Buying 5 meters of cloth for 150000 VND. Buying 25 meters of cloth of that kind, paying more than.......................... VND.   \n",
       "176                            Write the appropriate number in place of the dot: The value of the expression: 136.5 – 100 \\div 2.5 \\times 0.9 is:   \n",
       "172                                                                                                  The result of the calculation: 34.46 + 35.55   \n",
       "44                               A rectangle has a volume of 300dm^{3}, a length of 15dm, and a width of 5dm. So the height of the rectangle is :   \n",
       "67                                                                  The area of a rectangle with a length of 1.2dm and a width of \\frac{1}{3} is:   \n",
       "27                                                                                                  The area of a circle with radius r = 2 cm is:   \n",
       "90                                                                The proper number to fill in the dot so that 9m^{2} 8dm^{2} =........dm^{2} is:   \n",
       "154                                                                                                            2m^{2} 3cm^{2} =.............m^{2}   \n",
       "97                                                            The numbers 5.7; 6.02; 4.23; 4.32; 5.3 are written in order from least to greatest:   \n",
       "125                                                                                       Calculate the area ratios of the BDF and AEF triangles.   \n",
       "16                                                                                    Write the appropriate number in the dot: 21 km/h =... m/min   \n",
       "\n",
       "                                                                                answer  \\\n",
       "151                                                                              C. 10   \n",
       "32                                                                              D. 0,8   \n",
       "82                                                                   A. 9 \\frac{6}{10}   \n",
       "80                                                                           A. 1821,2   \n",
       "101                                                                            C. 0,05   \n",
       "112                                                                            D. 3,90   \n",
       "100                                                                            A. 2049   \n",
       "62                                                                            D. 2,257   \n",
       "156                                                                            B. 3,2%   \n",
       "41                                                                              B. 0,8   \n",
       "0                                                                   C. 50 000 000 đồng   \n",
       "70                                                                            C. 171,3   \n",
       "18                                                                         C. 0,18 giờ   \n",
       "86                                                                      D. 9 phần trăm   \n",
       "76                                                                            C. 62,5%   \n",
       "52                                                                             A. 9998   \n",
       "127                                                                    C. 121,5 dm^{3}   \n",
       "93                                                                          A. 75m^{2}   \n",
       "185                                                                          B. 37,5 %   \n",
       "116                                                                           A. 35,06   \n",
       "66                                                                            A. 34600   \n",
       "117                                                                            B. 7,99   \n",
       "10                                                                               B. 24   \n",
       "71                                                                      A. 45300 m^{2}   \n",
       "143                                                                               D. 5   \n",
       "25                                                                        B. 30 dm^{2}   \n",
       "111                                                                          C. 83 000   \n",
       "138                                                                             A. 45%   \n",
       "108                                                                    C. \\frac{11}{5}   \n",
       "107                                                                            D. 3,90   \n",
       "110                                                           A. 8; 8,76; 8,093; 8,901   \n",
       "59                                                                              B. 75%   \n",
       "146                                                                             D. 1,2   \n",
       "148                                                                       B. 8000m^{2}   \n",
       "34                                                                             B. 0,75   \n",
       "131                                                                       A. 1,15 phút   \n",
       "89                                                                          B. 1102 kg   \n",
       "162                                                                        A. 744m^{2}   \n",
       "168                                                                           B. 4,321   \n",
       "105                                                                          A. 750000   \n",
       "176                                                                           D. 105,5   \n",
       "172                                                                           B. 70,01   \n",
       "44                                                                             A. 10dm   \n",
       "67                                                                      D. 0,48 dm^{2}   \n",
       "27                                                                     D. 12,56 cm^{2}   \n",
       "90                                                                              B. 980   \n",
       "154                                                                          D. 20,003   \n",
       "97                                                       D. 4,23; 4,32; 5,3; 5,7; 6,02   \n",
       "125  A. 2 (BDF is a right triangle with a 90-degree angle, so the area ratio is 1:1:1)   \n",
       "16                                                                             B. 3500   \n",
       "\n",
       "                        old_answer  \n",
       "151                         B. 100  \n",
       "32                          D. 0,8  \n",
       "82               A. 9 \\frac{6}{10}  \n",
       "80                       A. 1821,2  \n",
       "101                         B. 0,5  \n",
       "112                       A. 3,900  \n",
       "100                        B. 2490  \n",
       "62                        B. 2,257  \n",
       "156                        B. 3,2%  \n",
       "41                          B. 0,8  \n",
       "0               C. 50 000 000 đồng  \n",
       "70                        A. 17,13  \n",
       "18                     C. 0,18 giờ  \n",
       "86                  D. 9 phần trăm  \n",
       "76                        C. 62,5%  \n",
       "52                         A. 9998  \n",
       "127                C. 121,5 dm^{3}  \n",
       "93                      A. 75m^{2}  \n",
       "185                      B. 37,5 %  \n",
       "116                        B. 35,6  \n",
       "66                        B. 30046  \n",
       "117                        B. 7,99  \n",
       "10                           B. 24  \n",
       "71                  A. 45300 m^{2}  \n",
       "143               C. \\frac{5}{100}  \n",
       "25                    B. 30 dm^{2}  \n",
       "111                        A. 8300  \n",
       "138                         A. 45%  \n",
       "108                C. \\frac{11}{5}  \n",
       "107                        B. 3,09  \n",
       "110      C. 6,732; 7; 7,009; 7,013  \n",
       "59                          B. 75%  \n",
       "146                         A. 1,2  \n",
       "148                   C. 3600m^{2}  \n",
       "34                         B. 0,75  \n",
       "131                   B. 1,25 phút  \n",
       "89                     C. 11020 kg  \n",
       "162                    A. 744m^{2}  \n",
       "168                         D. 4,4  \n",
       "105                       C. 30000  \n",
       "176                       D. 105,5  \n",
       "172                       B. 70,01  \n",
       "44                          D. 6dm  \n",
       "67                   A. 0,4 dm^{2}  \n",
       "27                 D. 12,56 cm^{2}  \n",
       "90                          C. 908  \n",
       "154                       C. 20,03  \n",
       "97   D. 4,23; 4,32; 5,3; 5,7; 6,02  \n",
       "125                         B. 1,5  \n",
       "16                         B. 3500  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"colwidth\", None)\n",
    "temp = pd.read_csv(\"submissions/submission_9.csv\", usecols=[\"id\", \"answer\"])\n",
    "df[\"old_answer\"] = temp[\"answer\"]\n",
    "df[[\"question\", \"answer\", \"old_answer\"]].sample(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"id\", \"answer\"]].to_csv(f\"submissions/submission_{VER}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zalo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
