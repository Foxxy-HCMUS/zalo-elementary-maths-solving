{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " count = 100\n"
     ]
    }
   ],
   "source": [
    "count = 100\n",
    "print(f\"{ count = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To make your changes take effect please reactivate your environment\n",
      "FlashAttention-2 is not installed, ignore this if you are not using FlashAttention.\n",
      "2024-01-15 00:55:21 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1 distributed training: True, 16-bits training: True\n",
      "2024-01-15 00:55:21 - INFO - __main__ - Model parameters ModelArguments(model_type='auto', model_name_or_path='/space/hotel/phit/contest/zalo/ElementaryMathsSolving/outputs-pt-zephyr-beta-v1', token=None, load_in_8bit=False, load_in_4bit=False, bnb_4bit_quant_type='nf4', use_bnb_nested_quant=False, tokenizer_name_or_path=None, cache_dir='./cache', use_fast_tokenizer=False, torch_dtype='float16', device_map='auto', trust_remote_code=True, model_revision='main', rope_scaling=None, use_flash_attention_2=False, shift_attn=False, neft_alpha=0)\n",
      "2024-01-15 00:55:21 - INFO - __main__ - Data parameters DataArguments(dataset_name=None, dataset_config_name=None, train_file_dir='./data/finetune', validation_file_dir=None, max_train_samples=None, max_eval_samples=None, ignore_pad_token_for_loss=True, overwrite_cache=False, validation_split_percentage=10, preprocessing_num_workers=4)\n",
      "2024-01-15 00:55:21 - INFO - __main__ - Training/evaluation parameters SFTConfig(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=False,\n",
      "ddp_timeout=30000,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=50,\n",
      "evaluation_strategy=steps,\n",
      "fp16=True,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=True,\n",
      "gradient_checkpointing_kwargs={'use_reentrant': False},\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=foxxy-hm/sft-zephyr-7b-beta-v1,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=3e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=info,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=outputs-sft-zephyr-beta-v1/runs/Jan15_00-55-21_i2x256-ai04,\n",
      "logging_first_step=True,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=cosine,\n",
      "max_grad_norm=1.0,\n",
      "max_seq_length=1024,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_torch,\n",
      "optim_args=None,\n",
      "output_dir=outputs-sft-zephyr-beta-v1,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=True,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=outputs-sft-zephyr-beta-v1,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=500,\n",
      "save_strategy=steps,\n",
      "save_total_limit=13,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.05,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.05,\n",
      ")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhoanganh6758\u001b[0m (\u001b[33mfoxyx\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.16.2 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/net/i2x256-ai03/hotel/phit/contest/zalo/ElementaryMathsSolving/wandb/run-20240115_005522-pok90lpd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33moutputs-sft-zephyr-beta-v1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/foxyx/huggingface\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/foxyx/huggingface/runs/pok90lpd\u001b[0m\n",
      "[INFO|tokenization_utils_base.py:2024] 2024-01-15 00:55:34,411 >> loading file tokenizer.model\n",
      "[INFO|tokenization_utils_base.py:2024] 2024-01-15 00:55:34,411 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2024] 2024-01-15 00:55:34,412 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2024] 2024-01-15 00:55:34,412 >> loading file tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2024] 2024-01-15 00:55:34,412 >> loading file tokenizer.json\n",
      "2024-01-15 00:55:34 - INFO - __main__ - train files: ['./data/finetune/convert_qualified_data.json', './data/finetune/grade4_mcq_v2.json', './data/finetune/convert_collect_data.json', './data/finetune/grade3_mcq_v2.json', './data/finetune/vietjack_finetune.json', './data/finetune/grade5_mcq_v2.json']\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./data/finetune)... Done. 0.4s\n",
      "Using custom data configuration default-dac5412022822e63\n",
      "2024-01-15 00:55:35 - INFO - datasets.builder - Using custom data configuration default-dac5412022822e63\n",
      "Loading Dataset Infos from /space/hotel/phit/miniconda3/envs/zalo/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
      "2024-01-15 00:55:35 - INFO - datasets.info - Loading Dataset Infos from /space/hotel/phit/miniconda3/envs/zalo/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
      "Overwrite dataset info from restored data version if exists.\n",
      "2024-01-15 00:55:35 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
      "Loading Dataset info from ./cache/json/default-dac5412022822e63/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "2024-01-15 00:55:35 - INFO - datasets.info - Loading Dataset info from ./cache/json/default-dac5412022822e63/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "Found cached dataset json (/mnt/net/i2x256-ai03/hotel/phit/contest/zalo/ElementaryMathsSolving/cache/json/default-dac5412022822e63/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "2024-01-15 00:55:35 - INFO - datasets.builder - Found cached dataset json (/mnt/net/i2x256-ai03/hotel/phit/contest/zalo/ElementaryMathsSolving/cache/json/default-dac5412022822e63/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "Loading Dataset info from /mnt/net/i2x256-ai03/hotel/phit/contest/zalo/ElementaryMathsSolving/cache/json/default-dac5412022822e63/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "2024-01-15 00:55:35 - INFO - datasets.info - Loading Dataset info from /mnt/net/i2x256-ai03/hotel/phit/contest/zalo/ElementaryMathsSolving/cache/json/default-dac5412022822e63/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "Using custom data configuration default-dac5412022822e63\n",
      "2024-01-15 00:55:36 - INFO - datasets.builder - Using custom data configuration default-dac5412022822e63\n",
      "Loading Dataset Infos from /space/hotel/phit/miniconda3/envs/zalo/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
      "2024-01-15 00:55:36 - INFO - datasets.info - Loading Dataset Infos from /space/hotel/phit/miniconda3/envs/zalo/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
      "Overwrite dataset info from restored data version if exists.\n",
      "2024-01-15 00:55:36 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
      "Loading Dataset info from ./cache/json/default-dac5412022822e63/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "2024-01-15 00:55:36 - INFO - datasets.info - Loading Dataset info from ./cache/json/default-dac5412022822e63/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "Found cached dataset json (/mnt/net/i2x256-ai03/hotel/phit/contest/zalo/ElementaryMathsSolving/cache/json/default-dac5412022822e63/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "2024-01-15 00:55:36 - INFO - datasets.builder - Found cached dataset json (/mnt/net/i2x256-ai03/hotel/phit/contest/zalo/ElementaryMathsSolving/cache/json/default-dac5412022822e63/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "Loading Dataset info from /mnt/net/i2x256-ai03/hotel/phit/contest/zalo/ElementaryMathsSolving/cache/json/default-dac5412022822e63/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "2024-01-15 00:55:36 - INFO - datasets.info - Loading Dataset info from /mnt/net/i2x256-ai03/hotel/phit/contest/zalo/ElementaryMathsSolving/cache/json/default-dac5412022822e63/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "Using custom data configuration default-dac5412022822e63\n",
      "2024-01-15 00:55:36 - INFO - datasets.builder - Using custom data configuration default-dac5412022822e63\n",
      "Loading Dataset Infos from /space/hotel/phit/miniconda3/envs/zalo/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
      "2024-01-15 00:55:36 - INFO - datasets.info - Loading Dataset Infos from /space/hotel/phit/miniconda3/envs/zalo/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
      "Overwrite dataset info from restored data version if exists.\n",
      "2024-01-15 00:55:36 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
      "Loading Dataset info from ./cache/json/default-dac5412022822e63/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "2024-01-15 00:55:36 - INFO - datasets.info - Loading Dataset info from ./cache/json/default-dac5412022822e63/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "Found cached dataset json (/mnt/net/i2x256-ai03/hotel/phit/contest/zalo/ElementaryMathsSolving/cache/json/default-dac5412022822e63/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "2024-01-15 00:55:36 - INFO - datasets.builder - Found cached dataset json (/mnt/net/i2x256-ai03/hotel/phit/contest/zalo/ElementaryMathsSolving/cache/json/default-dac5412022822e63/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "Loading Dataset info from /mnt/net/i2x256-ai03/hotel/phit/contest/zalo/ElementaryMathsSolving/cache/json/default-dac5412022822e63/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "2024-01-15 00:55:36 - INFO - datasets.info - Loading Dataset info from /mnt/net/i2x256-ai03/hotel/phit/contest/zalo/ElementaryMathsSolving/cache/json/default-dac5412022822e63/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "2024-01-15 00:55:36 - INFO - __main__ - Raw datasets: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question', 'id', 'answer', 'explanation', 'choices'],\n",
      "        num_rows: 7791\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['question', 'id', 'answer', 'explanation', 'choices'],\n",
      "        num_rows: 866\n",
      "    })\n",
      "})\n",
      "Loading cached shuffled indices for dataset at /mnt/net/i2x256-ai03/hotel/phit/contest/zalo/ElementaryMathsSolving/cache/json/default-dac5412022822e63/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f11d89d051412c70.arrow\n",
      "2024-01-15 00:55:36 - INFO - datasets.arrow_dataset - Loading cached shuffled indices for dataset at /mnt/net/i2x256-ai03/hotel/phit/contest/zalo/ElementaryMathsSolving/cache/json/default-dac5412022822e63/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f11d89d051412c70.arrow\n",
      "Process #0 will write at /mnt/net/i2x256-ai03/hotel/phit/contest/zalo/ElementaryMathsSolving/cache/json/default-dac5412022822e63/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0630b0d670792e87_00000_of_00004.arrow\n",
      "2024-01-15 00:55:36 - INFO - datasets.arrow_dataset - Process #0 will write at /mnt/net/i2x256-ai03/hotel/phit/contest/zalo/ElementaryMathsSolving/cache/json/default-dac5412022822e63/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0630b0d670792e87_00000_of_00004.arrow\n",
      "Process #1 will write at /mnt/net/i2x256-ai03/hotel/phit/contest/zalo/ElementaryMathsSolving/cache/json/default-dac5412022822e63/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0630b0d670792e87_00001_of_00004.arrow\n",
      "2024-01-15 00:55:36 - INFO - datasets.arrow_dataset - Process #1 will write at /mnt/net/i2x256-ai03/hotel/phit/contest/zalo/ElementaryMathsSolving/cache/json/default-dac5412022822e63/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0630b0d670792e87_00001_of_00004.arrow\n",
      "Process #2 will write at /mnt/net/i2x256-ai03/hotel/phit/contest/zalo/ElementaryMathsSolving/cache/json/default-dac5412022822e63/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0630b0d670792e87_00002_of_00004.arrow\n",
      "2024-01-15 00:55:36 - INFO - datasets.arrow_dataset - Process #2 will write at /mnt/net/i2x256-ai03/hotel/phit/contest/zalo/ElementaryMathsSolving/cache/json/default-dac5412022822e63/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0630b0d670792e87_00002_of_00004.arrow\n",
      "Process #3 will write at /mnt/net/i2x256-ai03/hotel/phit/contest/zalo/ElementaryMathsSolving/cache/json/default-dac5412022822e63/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0630b0d670792e87_00003_of_00004.arrow\n",
      "2024-01-15 00:55:36 - INFO - datasets.arrow_dataset - Process #3 will write at /mnt/net/i2x256-ai03/hotel/phit/contest/zalo/ElementaryMathsSolving/cache/json/default-dac5412022822e63/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0630b0d670792e87_00003_of_00004.arrow\n",
      "Loading cached processed dataset at /mnt/net/i2x256-ai03/hotel/phit/contest/zalo/ElementaryMathsSolving/cache/json/default-dac5412022822e63/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0630b0d670792e87_*_of_00004.arrow\n",
      "2024-01-15 00:55:36 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /mnt/net/i2x256-ai03/hotel/phit/contest/zalo/ElementaryMathsSolving/cache/json/default-dac5412022822e63/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0630b0d670792e87_*_of_00004.arrow\n",
      "Concatenating 4 shards\n",
      "2024-01-15 00:55:36 - INFO - datasets.arrow_dataset - Concatenating 4 shards\n",
      "Process #0 will write at /mnt/net/i2x256-ai03/hotel/phit/contest/zalo/ElementaryMathsSolving/cache/json/default-dac5412022822e63/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f99c7b6a4c87cae0_00000_of_00004.arrow\n",
      "2024-01-15 00:55:36 - INFO - datasets.arrow_dataset - Process #0 will write at /mnt/net/i2x256-ai03/hotel/phit/contest/zalo/ElementaryMathsSolving/cache/json/default-dac5412022822e63/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f99c7b6a4c87cae0_00000_of_00004.arrow\n",
      "Process #1 will write at /mnt/net/i2x256-ai03/hotel/phit/contest/zalo/ElementaryMathsSolving/cache/json/default-dac5412022822e63/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f99c7b6a4c87cae0_00001_of_00004.arrow\n",
      "2024-01-15 00:55:36 - INFO - datasets.arrow_dataset - Process #1 will write at /mnt/net/i2x256-ai03/hotel/phit/contest/zalo/ElementaryMathsSolving/cache/json/default-dac5412022822e63/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f99c7b6a4c87cae0_00001_of_00004.arrow\n",
      "Process #2 will write at /mnt/net/i2x256-ai03/hotel/phit/contest/zalo/ElementaryMathsSolving/cache/json/default-dac5412022822e63/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f99c7b6a4c87cae0_00002_of_00004.arrow\n",
      "2024-01-15 00:55:36 - INFO - datasets.arrow_dataset - Process #2 will write at /mnt/net/i2x256-ai03/hotel/phit/contest/zalo/ElementaryMathsSolving/cache/json/default-dac5412022822e63/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f99c7b6a4c87cae0_00002_of_00004.arrow\n",
      "Process #3 will write at /mnt/net/i2x256-ai03/hotel/phit/contest/zalo/ElementaryMathsSolving/cache/json/default-dac5412022822e63/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f99c7b6a4c87cae0_00003_of_00004.arrow\n",
      "2024-01-15 00:55:36 - INFO - datasets.arrow_dataset - Process #3 will write at /mnt/net/i2x256-ai03/hotel/phit/contest/zalo/ElementaryMathsSolving/cache/json/default-dac5412022822e63/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f99c7b6a4c87cae0_00003_of_00004.arrow\n",
      "Loading cached processed dataset at /mnt/net/i2x256-ai03/hotel/phit/contest/zalo/ElementaryMathsSolving/cache/json/default-dac5412022822e63/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f99c7b6a4c87cae0_*_of_00004.arrow\n",
      "2024-01-15 00:55:36 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /mnt/net/i2x256-ai03/hotel/phit/contest/zalo/ElementaryMathsSolving/cache/json/default-dac5412022822e63/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-f99c7b6a4c87cae0_*_of_00004.arrow\n",
      "Concatenating 4 shards\n",
      "2024-01-15 00:55:36 - INFO - datasets.arrow_dataset - Concatenating 4 shards\n",
      "2024-01-15 00:55:36 - INFO - __main__ - info: Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 866\n",
      "})\n",
      "2024-01-15 00:55:36 - INFO - __main__ - *** Load pretrained model ***\n",
      "2024-01-15 00:55:36 - INFO - __main__ - Train Dataset: Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 7791\n",
      "})\n",
      "2024-01-15 00:55:36 - INFO - __main__ - Evaluation Dataset: Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 866\n",
      "})\n",
      "2024-01-15 00:55:36 - INFO - __main__ - *** Model loaded! ***\n",
      "/space/hotel/phit/miniconda3/envs/zalo/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:158: UserWarning: You passed a model_id to the SFTTrainer. This will automatically create an `AutoModelForCausalLM` or a `PeftModel` (if you passed a `peft_config`) for you.\n",
      "  warnings.warn(\n",
      "[INFO|configuration_utils.py:739] 2024-01-15 00:55:36,968 >> loading configuration file config.json from cache at /space/hotel/phit/.cache/huggingface/hub/models--HuggingFaceH4--zephyr-7b-beta/snapshots/dc24cabd13eacd3ae3a5fe574bd645483a335a4a/config.json\n",
      "[INFO|configuration_utils.py:802] 2024-01-15 00:55:36,973 >> Model config MistralConfig {\n",
      "  \"_name_or_path\": \"HuggingFaceH4/zephyr-7b-beta\",\n",
      "  \"architectures\": [\n",
      "    \"MistralForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"model_type\": \"mistral\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pad_token_id\": 2,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 4096,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.36.2\",\n",
      "  \"use_cache\": false,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3344] 2024-01-15 00:55:37,067 >> loading weights file model.safetensors from cache at /space/hotel/phit/.cache/huggingface/hub/models--HuggingFaceH4--zephyr-7b-beta/snapshots/dc24cabd13eacd3ae3a5fe574bd645483a335a4a/model.safetensors.index.json\n",
      "[INFO|modeling_utils.py:1341] 2024-01-15 00:55:37,073 >> Instantiating MistralForCausalLM model under default dtype torch.float16.\n",
      "[INFO|configuration_utils.py:826] 2024-01-15 00:55:37,075 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 2,\n",
      "  \"use_cache\": false\n",
      "}\n",
      "\n",
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:15<00:00,  1.94s/it]\n",
      "[INFO|modeling_utils.py:4185] 2024-01-15 00:55:54,184 >> All model checkpoint weights were used when initializing MistralForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:4193] 2024-01-15 00:55:54,184 >> All the weights of MistralForCausalLM were initialized from the model checkpoint at HuggingFaceH4/zephyr-7b-beta.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MistralForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:781] 2024-01-15 00:55:54,316 >> loading configuration file generation_config.json from cache at /space/hotel/phit/.cache/huggingface/hub/models--HuggingFaceH4--zephyr-7b-beta/snapshots/dc24cabd13eacd3ae3a5fe574bd645483a335a4a/generation_config.json\n",
      "[INFO|configuration_utils.py:826] 2024-01-15 00:55:54,316 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2\n",
      "}\n",
      "\n",
      "Using custom data configuration default-525d55fd79d5906c\n",
      "2024-01-15 00:55:55 - INFO - datasets.builder - Using custom data configuration default-525d55fd79d5906c\n",
      "Loading Dataset Infos from /space/hotel/phit/miniconda3/envs/zalo/lib/python3.10/site-packages/datasets/packaged_modules/generator\n",
      "2024-01-15 00:55:55 - INFO - datasets.info - Loading Dataset Infos from /space/hotel/phit/miniconda3/envs/zalo/lib/python3.10/site-packages/datasets/packaged_modules/generator\n",
      "Overwrite dataset info from restored data version if exists.\n",
      "2024-01-15 00:55:55 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
      "Loading Dataset info from /space/hotel/phit/.cache/huggingface/datasets/generator/default-525d55fd79d5906c/0.0.0\n",
      "2024-01-15 00:55:55 - INFO - datasets.info - Loading Dataset info from /space/hotel/phit/.cache/huggingface/datasets/generator/default-525d55fd79d5906c/0.0.0\n",
      "Found cached dataset generator (/space/hotel/phit/.cache/huggingface/datasets/generator/default-525d55fd79d5906c/0.0.0)\n",
      "2024-01-15 00:55:55 - INFO - datasets.builder - Found cached dataset generator (/space/hotel/phit/.cache/huggingface/datasets/generator/default-525d55fd79d5906c/0.0.0)\n",
      "Loading Dataset info from /space/hotel/phit/.cache/huggingface/datasets/generator/default-525d55fd79d5906c/0.0.0\n",
      "2024-01-15 00:55:55 - INFO - datasets.info - Loading Dataset info from /space/hotel/phit/.cache/huggingface/datasets/generator/default-525d55fd79d5906c/0.0.0\n",
      "Using custom data configuration default-bcfba31a9c55ce23\n",
      "2024-01-15 00:55:55 - INFO - datasets.builder - Using custom data configuration default-bcfba31a9c55ce23\n",
      "Loading Dataset Infos from /space/hotel/phit/miniconda3/envs/zalo/lib/python3.10/site-packages/datasets/packaged_modules/generator\n",
      "2024-01-15 00:55:55 - INFO - datasets.info - Loading Dataset Infos from /space/hotel/phit/miniconda3/envs/zalo/lib/python3.10/site-packages/datasets/packaged_modules/generator\n",
      "Overwrite dataset info from restored data version if exists.\n",
      "2024-01-15 00:55:55 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
      "Loading Dataset info from /space/hotel/phit/.cache/huggingface/datasets/generator/default-bcfba31a9c55ce23/0.0.0\n",
      "2024-01-15 00:55:55 - INFO - datasets.info - Loading Dataset info from /space/hotel/phit/.cache/huggingface/datasets/generator/default-bcfba31a9c55ce23/0.0.0\n",
      "Found cached dataset generator (/space/hotel/phit/.cache/huggingface/datasets/generator/default-bcfba31a9c55ce23/0.0.0)\n",
      "2024-01-15 00:55:55 - INFO - datasets.builder - Found cached dataset generator (/space/hotel/phit/.cache/huggingface/datasets/generator/default-bcfba31a9c55ce23/0.0.0)\n",
      "Loading Dataset info from /space/hotel/phit/.cache/huggingface/datasets/generator/default-bcfba31a9c55ce23/0.0.0\n",
      "2024-01-15 00:55:55 - INFO - datasets.info - Loading Dataset info from /space/hotel/phit/.cache/huggingface/datasets/generator/default-bcfba31a9c55ce23/0.0.0\n",
      "[INFO|trainer.py:519] 2024-01-15 00:55:56,087 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:568] 2024-01-15 00:55:56,088 >> Using auto half precision backend\n",
      "/space/hotel/phit/miniconda3/envs/zalo/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:304: UserWarning: You passed `packing=True` to the SFTTrainer, and you are training your model with `max_steps` strategy. The dataset will be iterated until the `max_steps` are reached.\n",
      "  warnings.warn(\n",
      "2024-01-15 00:55:56 - INFO - __main__ - *** Train ***\n",
      "[INFO|trainer.py:1706] 2024-01-15 00:55:56,446 >> ***** Running training *****\n",
      "[INFO|trainer.py:1707] 2024-01-15 00:55:56,447 >>   Num examples = 3,470\n",
      "[INFO|trainer.py:1708] 2024-01-15 00:55:56,447 >>   Num Epochs = 2\n",
      "[INFO|trainer.py:1709] 2024-01-15 00:55:56,447 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1712] 2024-01-15 00:55:56,447 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1713] 2024-01-15 00:55:56,447 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1714] 2024-01-15 00:55:56,447 >>   Total optimization steps = 1,000\n",
      "[INFO|trainer.py:1715] 2024-01-15 00:55:56,453 >>   Number of trainable parameters = 54,525,952\n",
      "  0%|                                                  | 0/1000 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "  File \"/mnt/net/i2x256-ai03/hotel/phit/contest/zalo/ElementaryMathsSolving/sft.py\", line 810, in <module>\n",
      "    main()\n",
      "  File \"/mnt/net/i2x256-ai03/hotel/phit/contest/zalo/ElementaryMathsSolving/sft.py\", line 746, in main\n",
      "    train_result = trainer.train()\n",
      "  File \"/space/hotel/phit/miniconda3/envs/zalo/lib/python3.10/site-packages/trl/trainer/sft_trainer.py\", line 317, in train\n",
      "    output = super().train(*args, **kwargs)\n",
      "  File \"/space/hotel/phit/miniconda3/envs/zalo/lib/python3.10/site-packages/transformers/trainer.py\", line 1528, in train\n",
      "    return inner_training_loop(\n",
      "  File \"/space/hotel/phit/miniconda3/envs/zalo/lib/python3.10/site-packages/transformers/trainer.py\", line 1896, in _inner_training_loop\n",
      "    self.accelerator.clip_grad_norm_(\n",
      "  File \"/space/hotel/phit/miniconda3/envs/zalo/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1925, in clip_grad_norm_\n",
      "    self.unscale_gradients()\n",
      "  File \"/space/hotel/phit/miniconda3/envs/zalo/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1888, in unscale_gradients\n",
      "    self.scaler.unscale_(opt)\n",
      "  File \"/space/hotel/phit/miniconda3/envs/zalo/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py\", line 282, in unscale_\n",
      "    optimizer_state[\"found_inf_per_device\"] = self._unscale_grads_(optimizer, inv_scale, found_inf, False)\n",
      "  File \"/space/hotel/phit/miniconda3/envs/zalo/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py\", line 210, in _unscale_grads_\n",
      "    raise ValueError(\"Attempting to unscale FP16 gradients.\")\n",
      "ValueError: Attempting to unscale FP16 gradients.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33moutputs-sft-zephyr-beta-v1\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/foxyx/huggingface/runs/pok90lpd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ô∏è‚ö° View job at \u001b[34m\u001b[4mhttps://wandb.ai/foxyx/huggingface/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEyOTU1ODczNQ==/version_details/v6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240115_005522-pok90lpd/logs\u001b[0m\n",
      "ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 3025670) of binary: /space/hotel/phit/miniconda3/envs/zalo/bin/python\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/hotel/phit/miniconda3/envs/zalo/bin/accelerate\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/space/hotel/phit/miniconda3/envs/zalo/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py\", line 45, in main\n",
      "    args.func(args)\n",
      "  File \"/space/hotel/phit/miniconda3/envs/zalo/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 970, in launch_command\n",
      "    multi_gpu_launcher(args)\n",
      "  File \"/space/hotel/phit/miniconda3/envs/zalo/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 646, in multi_gpu_launcher\n",
      "    distrib_run.run(args)\n",
      "  File \"/space/hotel/phit/miniconda3/envs/zalo/lib/python3.10/site-packages/torch/distributed/run.py\", line 753, in run\n",
      "    elastic_launch(\n",
      "  File \"/space/hotel/phit/miniconda3/envs/zalo/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 132, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/space/hotel/phit/miniconda3/envs/zalo/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 246, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
      "============================================================\n",
      "sft.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "  <NO_OTHER_FAILURES>\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2024-01-15_00:56:20\n",
      "  host      : i2x256-ai04.sv4.uniquify.com\n",
      "  rank      : 0 (local_rank: 0)\n",
      "  exitcode  : 1 (pid: 3025670)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "!accelerate launch --config_file multi_gpu.yaml --num_processes=1 sft.py lora_config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To make your changes take effect please reactivate your environment\n",
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:06<00:00,  1.23it/s]\n",
      "/space/hotel/phit/miniconda3/envs/zalo/lib/python3.10/site-packages/transformers/generation/utils.py:1518: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n",
      "full answer process B. 45 000 000 ƒë·ªìng\n",
      "value only process 1 gi·ªù\n",
      "full answer process B. 4 l·∫ßn\n",
      "**********\n",
      "check tag A\n",
      "**********\n",
      "check tag B\n",
      "**********\n",
      "check tag C\n",
      "**********\n",
      "check tag D\n",
      "tag only process D\n",
      "**********\n",
      "check tag A\n",
      "**********\n",
      "check tag B\n",
      "**********\n",
      "check tag C\n",
      "**********\n",
      "check tag D\n",
      "tag only process D\n",
      "full answer process B. 5,621\n",
      "full answer process C. 21%\n",
      "full answer process D. 7 gi·ªù 77 ph√∫t\n",
      "full answer process C. 0,75\n",
      "full answer process C. 67,919\n",
      "full answer process B. 24\n",
      "full answer process D. 39870\n",
      "full answer process C. \\frac{7}{100}\n",
      "full answer process D. 5 ph·∫ßn m∆∞·ªùi\n",
      "full answer process B. 15%\n",
      "full answer process A. \\frac{1}{8}\n",
      "full answer process A. 21000\n",
      "full answer process A. 5,190\n",
      "full answer process C. 0,18 gi·ªù\n",
      "**********\n",
      "check tag A\n",
      "**********\n",
      "check tag B\n",
      "**********\n",
      "check tag C\n",
      "**********\n",
      "check tag D\n",
      "full answer process A. 50 000\n",
      "full answer process D. 37,5\n",
      "full answer process D. 10,5\n",
      "full answer process B. 30,05\n",
      "full answer process B. 1 gi·ªù 5 ph√∫t\n",
      "full answer process C. 36 dm^{2}\n",
      "full answer process A. 9,42 dm\n",
      "full answer process C. 6,28 cm^{2}\n",
      "full answer process B. 13800 dm^{3}\n",
      "full answer process A. 64%\n",
      "full answer process B. 3,760\n",
      "full answer process D. 201,07\n",
      "full answer process D. 0,8\n",
      "full answer process B. 20 ph√∫t\n",
      "full answer process B. 0,75\n",
      "full answer process B. 20 ph√∫t\n",
      "full answer process C. 1234\n",
      "full answer process C. 9 ph√∫t 36 gi√¢y\n",
      "full answer process B. 3,048\n",
      "full answer process B. 330 h·ªçc sinh\n",
      "full answer process B. \\frac{1}{2}\n",
      "full answer process C. 8\n",
      "full answer process B. 8 cm\n",
      "full answer process D. 707,65\n",
      "full answer process C. 8dm\n",
      "full answer process B. 55,0017\n",
      "full answer process B. 60%\n",
      "full answer process A. \\frac{9}{10}\n",
      "full answer process B. 4,8\n",
      "full answer process B. 125 m^{3}\n",
      "full answer process C. 6\n",
      "full answer process A. 850 m/ph√∫t\n",
      "full answer process A. 9998\n",
      "full answer process B. 20\n",
      "full answer process B. 3,82\n",
      "full answer process A. 200 t·∫°\n",
      "full answer process C. 50,24 dm^{2}\n",
      "full answer process C. 8dm\n",
      "full answer process A. 55,207\n",
      "full answer process B. 75%\n",
      "full answer process B. 110,5\n",
      "full answer process A. 55,0017\n",
      "**********\n",
      "check tag A\n",
      "**********\n",
      "check tag B\n",
      "**********\n",
      "check tag C\n",
      "full answer process C. 3,5%\n",
      "full answer process A. <\n",
      "full answer process C. 0,023\n",
      "full answer process C. 3046\n",
      "full answer process C. 48 dm^{2}\n",
      "full answer process B. 0,7\n",
      "full answer process B. 41,7\n",
      "full answer process A. 17,13\n",
      "full answer process C. 453,0 m^{2}\n",
      "full answer process B. 1527,4\n",
      "full answer process B. TrƒÉm\n",
      "full answer process B. 5000\n",
      "full answer process C. 150,07\n",
      "full answer process C. 62,5%\n",
      "full answer process A. 136\n",
      "full answer process D. 2,06\n",
      "full answer process B. 3,015 t·∫•n\n",
      "full answer process A. 1821,2\n",
      "full answer process C. 9,08\n",
      "full answer process A. 9 \\frac{6}{10}\n",
      "full answer process C. 7 ph·∫ßn trƒÉm\n",
      "full answer process C. 4,6\n",
      "full answer process C. 101,6\n",
      "full answer process B. 9 ph·∫ßn m∆∞·ªùi\n",
      "full answer process C. \\frac{5}{100}\n",
      "full answer process D. 0,080\n",
      "full answer process A. 11002 kg\n",
      "full answer process C. 908\n",
      "full answer process C. 8,60\n",
      "full answer process A. 40,392\n",
      "full answer process A. 75m^{2}\n",
      "full answer process C. 0,3kg\n",
      "full answer process D. 6,27 ha\n",
      "full answer process A. 72m^{2}\n",
      "full answer process A. 5,7; 6,02; 4,23; 4,32; 5,3\n",
      "value only process 25%\n",
      "full answer process A. \\frac{27}{10}\n",
      "full answer process A. 2049\n",
      "full answer process C. 0,05\n",
      "full answer process A. 900cm^{2}\n",
      "full answer process C. 1942,54\n",
      "full answer process B. 3,400\n",
      "full answer process A. 750000\n",
      "full answer process B. 2 \\frac{35}{100}\n",
      "full answer process C. 3,009\n",
      "full answer process D. \\frac{17}{5}\n",
      "full answer process B. 375,4\n",
      "full answer process D. 13; 12,47; 12,51; 12,001\n",
      "full answer process C. 83 000\n",
      "full answer process B. 3,09\n",
      "full answer process C. 240m^{2}\n",
      "full answer process C. 5,002\n",
      "full answer process C. 454,375\n",
      "full answer process A. 35,06\n",
      "full answer process D. 7,9\n",
      "full answer process A. \\frac{23}{5}\n",
      "full answer process D. H√†ng ph·∫ßn m∆∞·ªùi\n",
      "full answer process C. 6,90\n",
      "full answer process C. 64%\n",
      "full answer process C. 0,01\n",
      "full answer process C. 15 kg\n",
      "full answer process B. 2,24 l·∫ßn\n",
      "full answer process B. 1,5\n",
      "full answer process B. 60 ng√†y\n",
      "full answer process C. 121,5 dm^{3}\n",
      "full answer process D. 707,65\n",
      "full answer process B. 55,0017\n",
      "full answer process B. 3005\n",
      "full answer process B. 1,25 ph√∫t\n",
      "full answer process C. 16 cm^{2}\n",
      "full answer process A. 3,14 cm^{2}\n",
      "full answer process C. 0,32\n",
      "full answer process C. 2000\n",
      "full answer process A. 18,86\n",
      "full answer process B. 4,021 m^{3}\n",
      "full answer process A. 45%\n",
      "full answer process C. 66,7%\n",
      "full answer process D. 175 M^{2}\n",
      "full answer process A. 36 km/gi·ªù\n",
      "full answer process B. 1 716\n",
      "full answer process B. \\frac{5}{100}\n",
      "full answer process A. 62,54\n",
      "full answer process B. 1,07\n",
      "full answer process A. 1,2\n",
      "full answer process A. \\frac{8}{100}\n",
      "full answer process B. 8000m^{2}\n",
      "full answer process A. \\frac{17}{5}\n",
      "full answer process C. 75%\n",
      "full answer process D. 0,1\n",
      "full answer process B. 13 h√¨nh tam gi√°c\n",
      "full answer process C. 6,90\n",
      "full answer process A. 2,003\n",
      "full answer process A. 0,375\n",
      "full answer process C. 32%\n",
      "full answer process B. 315cm^{2}\n",
      "full answer process B. \\frac{7}{100}\n",
      "full answer process B. 34,06\n",
      "full answer process D. 9,95\n",
      "full answer process B. 7,54\n",
      "full answer process A. 744m^{2}\n",
      "full answer process B. 0,01\n",
      "full answer process C. 8750\n",
      "full answer process C. \\frac{18}{15}\n",
      "full answer process D. 1,003\n",
      "full answer process B. 0,080\n",
      "full answer process D. 4,4\n",
      "full answer process B. 95%\n",
      "full answer process A. 9000 ƒë·ªìng\n",
      "full answer process A. 20031\n",
      "full answer process C. 69,01\n",
      "full answer process D. 157 gi·ªù\n",
      "full answer process A. 70,54\n",
      "full answer process C. 2 km\n",
      "full answer process B. 110,5\n",
      "full answer process A. 55,0017\n",
      "full answer process B. \\frac{8}{100}\n",
      "full answer process A. 12,5\n",
      "full answer process C. \\frac{9}{100}\n",
      "full answer process B. 68,007\n",
      "full answer process B. 50,789\n",
      "full answer process B. 60%\n",
      "full answer process C. 45,1\n",
      "full answer process B. 37,5 %\n",
      "full answer process B. 4,562\n",
      "full answer process B. 3,04\n",
      "full answer process A. 183 dm^{2}\n"
     ]
    }
   ],
   "source": [
    "!python inference.py --model_name outputs-pt-zephyr-beta-v1/ --peft_model outputs-sft-zephyr-beta-v1/checkpoint-1000/ --load_in 8bit --max_new_tokens 512 --temperature 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To make your changes take effect please reactivate your environment\n",
      "/space/hotel/phit/miniconda3/envs/zalo/lib/python3.10/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11060). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "False\n",
      "/space/hotel/phit/miniconda3/envs/zalo/lib/python3.10/site-packages/bitsandbytes-0.41.2-py3.10.egg/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n",
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n",
      "Namespace(model_type='auto', base_model='/space/hotel/phit/contest/zalo/ElementaryMathsSolving/outputs-pt-zephyr-beta-v1', tokenizer_path='outputs-sft-zephyr-beta-v1/checkpoint-1000', lora_model='outputs-sft-zephyr-beta-v1/checkpoint-1000', resize_emb=False, output_dir='output', push_to_hub=False, hub_model_id='')\n",
      "Base model: /space/hotel/phit/contest/zalo/ElementaryMathsSolving/outputs-pt-zephyr-beta-v1\n",
      "LoRA model: outputs-sft-zephyr-beta-v1/checkpoint-1000\n",
      "Loading LoRA for causal language model\n",
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:03<00:00,  2.53it/s]\n",
      "Merging with merge_and_unload...\n",
      "Saving to Hugging Face format...\n",
      "/space/hotel/phit/miniconda3/envs/zalo/lib/python3.10/site-packages/transformers/integrations/peft.py:391: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/net/i2x256-ai03/hotel/phit/contest/zalo/ElementaryMathsSolving/merge_peft_adapter.py\", line 138, in <module>\n",
      "    main()\n",
      "  File \"/mnt/net/i2x256-ai03/hotel/phit/contest/zalo/ElementaryMathsSolving/merge_peft_adapter.py\", line 128, in main\n",
      "    base_model.save_pretrained(\n",
      "  File \"/space/hotel/phit/miniconda3/envs/zalo/lib/python3.10/site-packages/transformers/modeling_utils.py\", line 2260, in save_pretrained\n",
      "    state_dict = model_to_save.get_adapter_state_dict()\n",
      "  File \"/space/hotel/phit/miniconda3/envs/zalo/lib/python3.10/site-packages/transformers/integrations/peft.py\", line 417, in get_adapter_state_dict\n",
      "    adapter_name = self.active_adapter()\n",
      "  File \"/space/hotel/phit/miniconda3/envs/zalo/lib/python3.10/site-packages/transformers/integrations/peft.py\", line 395, in active_adapter\n",
      "    return self.active_adapters()[0]\n",
      "  File \"/space/hotel/phit/miniconda3/envs/zalo/lib/python3.10/site-packages/transformers/integrations/peft.py\", line 385, in active_adapters\n",
      "    if isinstance(active_adapters, str):\n",
      "UnboundLocalError: local variable 'active_adapters' referenced before assignment\n"
     ]
    }
   ],
   "source": [
    "!python merge_peft_adapter.py --model_type auto \\\n",
    "                            --base_model /space/hotel/phit/contest/zalo/ElementaryMathsSolving/outputs-pt-zephyr-beta-v1 \\\n",
    "                             --tokenizer_path outputs-sft-zephyr-beta-v1/checkpoint-1000 \\\n",
    "                             --lora_model outputs-sft-zephyr-beta-v1/checkpoint-1000 \\\n",
    "                             --output_dir output "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zalo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
